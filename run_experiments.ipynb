{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTornament Size could be more \"flexible\"\\nFor instance, 5% of pop_size (but has to be >1)\\n    t_size_val = int(params[\\'pop_size\\'] * 0.05) \\n    t_sizes = [max(2, t_size_val)] * n_objs\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DATASETS A USAR, SENDO QUE POR AGORA QUEREMOS SÓ UM GRÁFICO PARA CADA #APAGAR\n",
    "\"\"\"\n",
    "load_resid_build_sale_price(X_y=True):\n",
    "    Loads and returns the RESIDNAME data set (regression). Taken from https://archive.ics.uci.edu/dataset/437/residential+building+data+set\n",
    "\n",
    "load_istanbul(X_y=True):\n",
    "    Loads and returns the Istanbul data set (regression). Taken from https://docs.1010data.com/MachineLearningExamples/IstanbulDataSet.html.\n",
    "\n",
    "load_airfoil(X_y=True):\n",
    "    - Number of data instances: 1503;\n",
    "    - Number of input features: 5;\n",
    "    - Target's range: [103.38-140.987].\n",
    "\n",
    "load_bike_sharing(X_y=True):\n",
    "    - Number of data instances: 17389;\n",
    "    - Number of input features: 13;\n",
    "    - Target's range: [22, 8714].                            x\n",
    "\n",
    "load_boston(X_y=True):\n",
    "    - Number of data instances: 506;\n",
    "    - Number of input features: 13;\n",
    "    - Target's range: [5, 50].\n",
    "\n",
    " load_concrete_slump\n",
    "    - Number of data instances: 103;\n",
    "    - Number of input features: 7;\n",
    "    - Target's range: [0, 29].\n",
    "\n",
    "load_concrete_strength(X_y=True):\n",
    "    - Number of data instances: 1005;\n",
    "    - Number of input features: 8;\n",
    "    - Target's range: [2.331807832, 82.5992248].\n",
    "\n",
    "load_diabetes(X_y=True):\n",
    "    - Number of data instances: 442;\n",
    "    - Number of input features: 10;\n",
    "    - Target's range: [25, 346].\n",
    "\n",
    "load_efficiency_heating(X_y=True):\n",
    "    - Number of data instances: 768;\n",
    "    - Number of input features: 8;\n",
    "    - Target's range: [6.01, 43.1].\n",
    "\n",
    "load_efficiency_cooling(X_y=True):<-------------- usar este\n",
    "    - Number of data instances: 768;\n",
    "    - Number of input features: 8;\n",
    "    - Target's range: [10.9, 48.03].\n",
    "\n",
    "load_forest_fires(X_y=True):\n",
    "    - Number of data instances: 513;\n",
    "    - Number of input features: 43;\n",
    "    - Target's range: [0.0, 6.995619625423205].\n",
    "\n",
    "load_parkinson_updrs(X_y=True):\n",
    "    - Number of data instances: 5875;                           x\n",
    "    - Number of input features: 19;\n",
    "    - Target's range: [7.0, 54.992].\n",
    "\n",
    "load_ld50(X_y=True):  <-----------------usar este\n",
    "    - Number of data instances: 234;\n",
    "    - Number of input features: 626;\n",
    "    - Target's range: [0.25, 8900.0].\n",
    "\n",
    "load_ppb(X_y=True): \n",
    "    - Number of data instances: 131;\n",
    "    - Number of input features: 626;\n",
    "    - Target's range: [0.5, 100.0]\n",
    "\n",
    "load_bioav(X_y=True):\n",
    "    - Number of data instances: 358;\n",
    "    - Number of input features: 241;\n",
    "    - Target's range: [0.4, 100.0].\n",
    "\"\"\"\n",
    "#APAGAR: hyperparameters\n",
    "\"\"\"\n",
    "(function) def mo_gp(\n",
    "    X_train: Tensor,\n",
    "    y_train: Tensor,\n",
    "    X_test: Tensor = None,\n",
    "    y_test: Tensor = None,\n",
    "    dataset_name: str = None,\n",
    "    pop_size: int = gp_parameters[\"pop_size\"],\n",
    "    selector_strategy: str = \"nested_tournament\",\n",
    "    survival_strategy: str = \"nsga2\",\n",
    "    offspring_size: int | None = None,\n",
    "    n_iter: int = gp_solve_parameters[\"n_iter\"],\n",
    "    p_xo: float = gp_parameters['p_xo'],\n",
    "    n_elites: int = gp_solve_parameters[\"n_elites\"],\n",
    "    max_depth: int | None = gp_solve_parameters[\"max_depth\"],\n",
    "    init_depth: int = gp_pi_init[\"init_depth\"],\n",
    "    log_path: str = None,\n",
    "    seed: int = gp_parameters[\"seed\"],\n",
    "    log_level: int = gp_solve_parameters[\"log\"],\n",
    "    verbose: int = gp_solve_parameters[\"verbose\"],\n",
    "    fitness_functions: list = mo_parameters[\"mo_fitness_functions\"],\n",
    "    minimization_flags: list = mo_parameters[\"mo_minimization_flags\"],\n",
    "    tournament_sizes: list = mo_parameters[\"mo_tournament_sizes\"],\n",
    "    ideal_candidate_values: list | None = None,\n",
    "    initializer: str = gp_parameters[\"initializer\"],\n",
    "    n_jobs: int = gp_solve_parameters[\"n_jobs\"],\n",
    "    prob_const: float = gp_pi_init[\"p_c\"],\n",
    "    tree_functions: list = list(FUNCTIONS.keys()),\n",
    "    tree_constants: list = [float(key.replace(\"constant_\", \"\").replace(\"_\", \"-\")) for key in CONSTANTS],\n",
    "    test_elite: bool = gp_solve_parameters[\"test_elite\"]\n",
    ") -> Any\n",
    "Main function to execute the Multi-Objective Genetic Programming (MOGP) algorithm on specified datasets\n",
    "\n",
    "Parameters\n",
    "X_train: : torch.Tensor\n",
    "Training input data.\n",
    "\n",
    "y_train: : torch.Tensor\n",
    "Training output data.\n",
    "\n",
    "X_test: : torch.Tensor , optional\n",
    "Testing input data.\n",
    "\n",
    "y_test: : torch.Tensor , optional\n",
    "Testing output data.\n",
    "\n",
    "dataset_name : str, optional\n",
    "Dataset name, for logging purposes\n",
    "\n",
    "pop_size : int, optional\n",
    "The population size for the genetic programming algorithm (default is 100).\n",
    "\n",
    "selector_strategy : str, optional\n",
    "The selection strategy for parent selection. Options are \"nested_tournament\" or \"nsga2\" (default is \"nested_tournament\").\n",
    "\n",
    "survival_strategy : str, optional\n",
    "The survival selection strategy. Options are \"nsga2\" or \"generational\" (default is \"nsga2\").\n",
    "\n",
    "offspring_size : int, optional\n",
    "The size of the offspring population to be generated in each generation. If None, it defaults to pop_size.\n",
    "\n",
    "n_iter : int, optional\n",
    "The number of iterations for the genetic programming algorithm (default is 100).\n",
    "\n",
    "p_xo : float, optional\n",
    "The probability of crossover in the genetic programming algorithm. Must be a number between 0 and 1 (default is 0.8).\n",
    "\n",
    "n_elites : int, optional\n",
    "The number of elites.\n",
    "\n",
    "max_depth : int, optional\n",
    "The maximum depth for the GP trees.\n",
    "\n",
    "init_depth : int, optional\n",
    "The depth value for the initial GP trees population.\n",
    "\n",
    "log_path : str, optional\n",
    "The path where is created the log directory where results are saved. Defaults to os.path.join(os.getcwd(), \"log\", \"mo_gp.csv\")\n",
    "\n",
    "seed : int, optional\n",
    "Seed for the randomness\n",
    "\n",
    "log_level : int, optional\n",
    "Level of detail to utilize in logging.\n",
    "\n",
    "verbose : int, optional\n",
    "Level of detail to include in console output.\n",
    "\n",
    "fitness_functions : list, optional\n",
    "A list of fitness function names, one for each objective. (Default is from mo_parameters)\n",
    "\n",
    "minimization_flags : list, optional\n",
    "A list of booleans indicating if each corresponding objective is for minimization (True) or maximization (False). (Default is from mo_parameters)\n",
    "\n",
    "tournament_sizes : list, optional\n",
    "A list of integers defining the tournament size for each objective during Nested Tournament Selection. (Default is from mo_parameters)\n",
    "\n",
    "ideal_candidate_values : list, optional\n",
    "A list of ideal candidate values for each objective to guide elite selection. If None, defaults uses first-objective logic.\n",
    "\n",
    "initializer : str, optional\n",
    "The strategy for initializing the population (e.g., \"grow\", \"full\", \"rhh\").\n",
    "\n",
    "n_jobs : int, optional\n",
    "Number of parallel jobs to run (default is 1).\n",
    "\n",
    "prob_const : float, optional\n",
    "The probability of a constant being chosen rather than a terminal in trees creation (default: 0.2).\n",
    "\n",
    "tree_functions : list, optional\n",
    "List of allowed functions that can appear in the trees. Check documentation for the available functions.\n",
    "\n",
    "tree_constants : list, optional\n",
    "List of constants allowed to appear in the trees.\n",
    "\n",
    "test_elite : bool, optional\n",
    "Whether to test the elite individual on the test set after each generation.\n",
    "\n",
    "Returns\n",
    "MultiObjectiveTree\n",
    "Returns the best individual according to the tracking strategy at the last generation.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Tornament Size could be more \"flexible\"\n",
    "For instance, 5% of pop_size (but has to be >1)\n",
    "    t_size_val = int(params['pop_size'] * 0.05) \n",
    "    t_sizes = [max(2, t_size_val)] * n_objs\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#APAGAR CENÁRIO CD ELITISM\n",
    "#1. best candidate elitism; \n",
    "#2. rank+ CD elitism\n",
    "# Para criar o cenário de NT + rank/CD elitism: Rank Elitism no Generational, terias de alterar o main_mo_gp.py. \n",
    "# # Em main_mo_gp.py\n",
    "\n",
    "# def mo_gp(..., elitism_type=\"standard\", ...): # Novo argumento\n",
    "    \n",
    "#     # ... (validações) ...\n",
    "\n",
    "#     # Lógica de Elitismo Atualizada\n",
    "#     if ideal_candidate_values is not None:\n",
    "#         gp_parameters[\"find_elit_func\"] = lambda pop, n, min_flags, fronts=None: \\\n",
    "#             find_mo_elites_ideal_candidate(pop, n, min_flags, ideal_candidate_values)\n",
    "            \n",
    "#     elif survival_strategy == \"generational\" and n_elites > 0:\n",
    "#         if elitism_type == \"first_obj\":\n",
    "#              # Elitismo no 1º Objetivo\n",
    "#              gp_parameters[\"find_elit_func\"] = lambda pop, n, min_flags, fronts=None: \\\n",
    "#                  find_mo_elites_default(pop, n, min_flags, use_first_obj=True, fronts=fronts)\n",
    "#         else:\n",
    "#              # Elitismo Padrão (Rank + CD) -> O que tu queres adicionar\n",
    "#              gp_parameters[\"find_elit_func\"] = find_mo_elites_default\n",
    "             \n",
    "#     else:\n",
    "#         gp_parameters[\"find_elit_func\"] = find_mo_elites_default\n",
    "\n",
    "\n",
    "\n",
    "# 'NT_1st_Obj_Elitism': {\n",
    "#         'selector': 'nested_tournament',\n",
    "#         'survival': 'generational',\n",
    "#         'n_elites': 1,\n",
    "#         'elitism_type': 'first_obj', # <-- Flag Nova\n",
    "#         'ideal': None\n",
    "#     },\n",
    "\n",
    "# 'NT_Rank_CD_Elitism': { \n",
    "#         'selector': 'nested_tournament',\n",
    "#         'survival': 'generational',\n",
    "#         'n_elites': 1,\n",
    "#         'elitism_type': 'standard',\n",
    "#         'ideal': None\n",
    "#     }\n",
    "\n",
    "\n",
    "# # Dentro do loop de execução\n",
    "# elitism_type = scen_config.get('elitism_type', 'standard')\n",
    "\n",
    "# elite = mo_gp(\n",
    "#     # ... outros argumentos ...\n",
    "#     elitism_type=elitism_type,\n",
    "#     # ...\n",
    "# )\n",
    "####################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALTERAÇÕES (APAGAR):\n",
    "#- log_path & log_level: posso criar um log =5 e fazer hard coded o que quero armazenar. LOG=5 DO QUE FOR PRECISO (AUDIO PROF. KARINA); \n",
    "#- ideal candidate ser atualizado; BEST INDIVIDUAL IMPLEMENTAR BEM E DEIXA DE SER USER DEFINED; \n",
    "#Manter um histórico utilizando a pop. que evolui e para cada objetivo de cada vez que encontra um indivíduo \n",
    "#com erro menor de sempre, aquele valor atualizada: lista que muda dinamicamente e inicializada com os melhores valores da pop inicial\n",
    "\n",
    "#- implementar bem o CD como elitism (mesmo acima) ADICIONAR ELITISMO DE RANK+CD PARA NT\n",
    "#- tournament size mas ver com \"Tornament Size could be ...\"\n",
    "#- #RANDOM_SEARCH DEIXA DE SE FAZER APAGAR\n",
    "#- QUAIS ERAM AS FITNESS FUNCTIONS? APAGAR: TEMOS 3 NOVAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import KFold, ParameterGrid\n",
    "from slim_gsgp.main_mo_gp import mo_gp\n",
    "from slim_gsgp.datasets.data_loader import (\n",
    "     load_efficiency_cooling, load_ld50\n",
    ")\n",
    "\n",
    "# Configuration\n",
    "RANDOM_SEED = 37\n",
    "np.random.seed(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "# Datasets to Test (we need to import them first)\n",
    "DATASETS = {\n",
    "    #'Cooling': load_efficiency_cooling,\n",
    "    'Toxicity': load_ld50,\n",
    "}\n",
    "\n",
    "\n",
    "# Objective Configurations\n",
    "OBJECTIVE_SETS = {\n",
    "    '2_Objs': {\n",
    "        'funcs': [\"rmse\", \"size\"],\n",
    "        'flags': [True, True] # Min, Min\n",
    "    },\n",
    "    '3_Objs': {\n",
    "        'funcs': [\"rmse\", \"size\", \"features\"],\n",
    "        'flags': [True, True, True]\n",
    "    },\n",
    "    '5_Objs': {\n",
    "        'funcs': [\"rmse\", \"size\", \"features\", \"nao\", \"naoc\"],\n",
    "        'flags': [True, True, True, True, True]\n",
    "    }\n",
    "}\n",
    "\n",
    "SCENARIOS = {\n",
    "    'NSGA-II_Pure': {\n",
    "        'selector': 'nsga2',\n",
    "        'survival': 'nsga2',\n",
    "        'n_elites': 0, \n",
    "        'elitism_strategy': 'nsga2'\n",
    "    },\n",
    "    'NT_NSGA-II': {\n",
    "        'selector': 'nested_tournament',\n",
    "        'survival': 'nsga2',\n",
    "        'n_elites': 0,\n",
    "        'elitism_strategy': 'nsga2'\n",
    "    },\n",
    "    'NT_No_Elitism': {\n",
    "        'selector': 'nested_tournament',\n",
    "        'survival': 'generational',\n",
    "        'n_elites': 0,\n",
    "        'elitism_strategy': 'nsga2'\n",
    "    },\n",
    "    'NT_1st_Obj_Elitism': {\n",
    "        'selector': 'nested_tournament',\n",
    "        'survival': 'generational',\n",
    "        'n_elites': 1,\n",
    "        'elitism_strategy': 'first_obj' #uses RMSE\n",
    "    },\n",
    "    'NT_Rank_CD_Elitism': {\n",
    "        'selector': 'nested_tournament',\n",
    "        'survival': 'generational',\n",
    "        'n_elites': 1,\n",
    "        'elitism_strategy': 'nsga2' #Rank + CD\n",
    "    },\n",
    "    'NT_Ideal_Cand_Elitism': {\n",
    "        'selector': 'nested_tournament',\n",
    "        'survival': 'generational',\n",
    "        'n_elites': 1,\n",
    "        'elitism_strategy': 'ideal_point' #dynamic ideal point\n",
    "    }\n",
    "}\n",
    "\n",
    "# Hyperparameter Grid for Inner CV\n",
    "PARAM_GRID = {\n",
    "    'pop_size': [100, 250, 500],\n",
    "    'n_iter': [500],                                            #APAGAR: Pode ser que seja um valor muito alto\n",
    "    'p_xo': [0.2, 0.5, 0.8],\n",
    "    'prob_const': [0.2],     \n",
    "    'max_depth': [17],       #default\n",
    "    'initializer': ['rhh'],  #default\n",
    "    \"init_depth\": [6],       #default\n",
    "    \"seed\": [74],            #default\n",
    "    #\"verbose\": [1],          #APAGAR\n",
    "    \"n_jobs\": [1],           #default\n",
    "    \"test_elite\": [True]    \n",
    "}\n",
    "\n",
    "# PARAM_GRID = {\n",
    "#     'pop_size': [10, 11],\n",
    "#     'n_iter': [5],\n",
    "#     'p_xo': [0.8],\n",
    "#     'prob_const': [0.2],    \n",
    "#     'max_depth': [6],\n",
    "#     'initializer': ['rhh'], \n",
    "#     \"init_depth\": [6],      \n",
    "#     \"seed\": [74],           \n",
    "#     \"n_jobs\": [1],\n",
    "#     \"test_elite\": [True]    \n",
    "# }\n",
    "\n",
    "##################################JUST COMMENTS##################################\n",
    "#Other parameters will remain default:\n",
    "###offspring_size###\n",
    "# if offspring_size is None:\n",
    "#     n_offspring = self.pop_size\n",
    "\n",
    "###n_elites###\n",
    "# it depends on the scenario being used\n",
    "\n",
    "###log_path & log_level###\n",
    "#posso criar um log =5 e fazer hard coded o que quero armazenar    APAGAR\n",
    "# it depends on dataset, scenario, fold, hyperparams\n",
    "# APAGAR: find out what information we need to log (its better to log more info and then ignore what is not needed than the opposite)\n",
    "\n",
    "###fitness_functions, minimization_flags###\n",
    "#it depends on the scenario being used: OBJECTIVE_SETS (Ok)\n",
    "\n",
    "###tournament_sizes###\n",
    "# Tournament sizes need to be dynamic based on n_objectives, handled in loop. When using Nested Tournament Selection, but for now we will fix it \n",
    "\n",
    "###ideal_candidate_values###\n",
    "# it can no longer be user defined      \n",
    "\n",
    "### \"test_elite\": True###\n",
    "\n",
    "### tree_functions ###\n",
    "# FUNCTIONS = {\n",
    "#     'add': {'function': torch.add, 'arity': 2},\n",
    "#     'subtract': {'function': torch.sub, 'arity': 2},\n",
    "#     'multiply': {'function': torch.mul, 'arity': 2},\n",
    "#     'divide': {'function': utils.protected_div, 'arity': 2},\n",
    "#     'mod': {'function': utils.protected_mod, 'arity': 2},\n",
    "#     'pow': {'function': utils.protected_pow, 'arity': 2},\n",
    "# }\n",
    "\n",
    "### tree_constants ###\n",
    "# I changed what originaly was in gp_config.py to the following:\n",
    "# random.seed(47)\n",
    "# CONSTANTS = {\n",
    "#     f'constant_{i}': lambda _, val=random.uniform(-1, 1): torch.tensor(val)\n",
    "#     for i in range(10)\n",
    "# }\n",
    "#################################################################################\n",
    "\n",
    "\n",
    "K_OUTER = 15\n",
    "K_INNER = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#e5c120ff; padding:1px; border-radius:10px;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Evaluation Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For each dataset: load data\n",
    "    # For each Outer fold: (14 folds for train + 1 fold for test each time) -> what will be use to track scores\n",
    "        # For each objective structure (Obj: 2, 3, 5)\n",
    "            # For each Scenario\n",
    "                # For each combination of current_grid# Estrutura: \n",
    "    \n",
    "#./log_mo/DATASET/SCENARIO/OBJECTIVES/fold_X.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #APAGAR \n",
    "# import os\n",
    "# import time\n",
    "# import random\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import torch\n",
    "# from sklearn.model_selection import KFold, ParameterGrid\n",
    "# from slim_gsgp.main_mo_gp import mo_gp\n",
    "# from slim_gsgp.datasets.data_loader import load_efficiency_cooling, load_ld50\n",
    "\n",
    "# # ==========================================\n",
    "# # Configuration\n",
    "# # ==========================================\n",
    "# RANDOM_SEED = 37\n",
    "# np.random.seed(RANDOM_SEED)\n",
    "# random.seed(RANDOM_SEED)\n",
    "# torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "# # Datasets\n",
    "# DATASETS = {\n",
    "#     # 'Cooling': load_efficiency_cooling,\n",
    "#     'Toxicity': load_ld50,\n",
    "# }\n",
    "\n",
    "# # Objective Configurations\n",
    "# OBJECTIVE_SETS = {\n",
    "#     '2_Objs': {\n",
    "#         'funcs': [\"rmse\", \"size\"],\n",
    "#         'flags': [True, True] # Min, Min\n",
    "#     },\n",
    "#     '3_Objs': {\n",
    "#         'funcs': [\"rmse\", \"size\", \"features\"],\n",
    "#         'flags': [True, True, True]\n",
    "#     },\n",
    "#     '5_Objs': {\n",
    "#         'funcs': [\"rmse\", \"size\", \"features\", \"nao\", \"naoc\"],\n",
    "#         'flags': [True, True, True, True, True]\n",
    "#     }\n",
    "# }\n",
    "\n",
    "# # Scenarios\n",
    "# SCENARIOS = {\n",
    "#     'NSGA-II_Pure': {\n",
    "#         'selector': 'nsga2', 'survival': 'nsga2', 'n_elites': 0, 'elitism_strategy': 'nsga2'\n",
    "#     },\n",
    "#     'NT_NSGA-II': {\n",
    "#         'selector': 'nested_tournament', 'survival': 'nsga2', 'n_elites': 0, 'elitism_strategy': 'nsga2'\n",
    "#     },\n",
    "#     'NT_No_Elitism': {\n",
    "#         'selector': 'nested_tournament', 'survival': 'generational', 'n_elites': 0, 'elitism_strategy': 'nsga2'\n",
    "#     },\n",
    "#     'NT_1st_Obj_Elitism': {\n",
    "#         'selector': 'nested_tournament', 'survival': 'generational', 'n_elites': 1, 'elitism_strategy': 'first_obj'\n",
    "#     },\n",
    "#     'NT_Rank_CD_Elitism': {\n",
    "#         'selector': 'nested_tournament', 'survival': 'generational', 'n_elites': 1, 'elitism_strategy': 'nsga2'\n",
    "#     },\n",
    "#     'NT_Ideal_Cand_Elitism': {\n",
    "#         'selector': 'nested_tournament', 'survival': 'generational', 'n_elites': 1, 'elitism_strategy': 'ideal_point'\n",
    "#     }\n",
    "# }\n",
    "\n",
    "# # Hyperparameter Grid\n",
    "# PARAM_GRID = {\n",
    "#     'pop_size': [100, 250, 500],\n",
    "#     'n_iter': [500],\n",
    "#     'p_xo': [0.2, 0.5, 0.8],\n",
    "#     'prob_const': [0.2],    \n",
    "#     'max_depth': [17],      \n",
    "#     'initializer': ['rhh'], \n",
    "#     \"init_depth\": [6],      \n",
    "#     \"seed\": [74],           \n",
    "#     #\"verbose\": [1],   #APAGAR      \n",
    "#     \"n_jobs\": [1],          \n",
    "#     \"test_elite\": [True]    \n",
    "# }\n",
    "\n",
    "# K_OUTER = 15\n",
    "# K_INNER = 5\n",
    "\n",
    "# # ==========================================\n",
    "# # Main Execution Loop\n",
    "# # ==========================================\n",
    "# if __name__ == \"__main__\":\n",
    "#     for ds_name, loader_func in DATASETS.items():\n",
    "#         print(f\"\\n{'='*40}\\nDataset: {ds_name}\\n{'='*40}\")\n",
    "        \n",
    "#         # Load Data\n",
    "#         try:\n",
    "#             X, y = loader_func(X_y=True)\n",
    "#         except Exception as e:\n",
    "#             print(f\"[CRITICAL] Failed to load dataset {ds_name}: {e}\")\n",
    "#             continue\n",
    "        \n",
    "#         # Outer CV\n",
    "#         kf_outer = KFold(n_splits=K_OUTER, shuffle=True, random_state=RANDOM_SEED)\n",
    "        \n",
    "#         for outer_fold, (train_idx, test_idx) in enumerate(kf_outer.split(X, y)):\n",
    "#             print(f\"\\n  > Outer Fold {outer_fold+1}/{K_OUTER}\")\n",
    "            \n",
    "#             X_train_outer = X[train_idx]\n",
    "#             y_train_outer = y[train_idx]\n",
    "#             X_test_outer = X[test_idx]\n",
    "#             y_test_outer = y[test_idx]\n",
    "            \n",
    "#             # Inner CV Setup\n",
    "#             kf_inner = KFold(n_splits=K_INNER, shuffle=True, random_state=RANDOM_SEED)\n",
    "            \n",
    "#             for obj_set_name, obj_config in OBJECTIVE_SETS.items():\n",
    "#                 n_objs = len(obj_config['funcs'])\n",
    "#                 print(f\"    > Objectives: {obj_set_name}\")\n",
    "                \n",
    "#                 for scen_name, scen_config in SCENARIOS.items():\n",
    "#                     print(f\"      > Scenario: {scen_name}\")\n",
    "                    \n",
    "#                     # 1. Hyperparameter Tuning (Inner CV)\n",
    "#                     best_params = None\n",
    "#                     best_inner_score = float('inf')\n",
    "#                     current_grid = list(ParameterGrid(PARAM_GRID))\n",
    "                    \n",
    "#                     for params in current_grid:\n",
    "#                         t_sizes = [2] * n_objs\n",
    "#                         inner_rmse_scores = []\n",
    "\n",
    "#                         # Inner Loop\n",
    "#                         for inner_t_idx, inner_v_idx in kf_inner.split(X_train_outer, y_train_outer):\n",
    "#                             X_in_t, y_in_t = X_train_outer[inner_t_idx], y_train_outer[inner_t_idx]\n",
    "#                             X_in_v, y_in_v = X_train_outer[inner_v_idx], y_train_outer[inner_v_idx]\n",
    "                            \n",
    "#                             try:\n",
    "#                                 elite = mo_gp(\n",
    "#                                     X_train=X_in_t, y_train=y_in_t,\n",
    "#                                     X_test=X_in_v, y_test=y_in_v,\n",
    "#                                     dataset_name=f\"{ds_name}_inner\",\n",
    "#                                     fitness_functions=obj_config['funcs'],\n",
    "#                                     minimization_flags=obj_config['flags'],\n",
    "#                                     tournament_sizes=t_sizes,\n",
    "#                                     elitism_strategy=scen_config['elitism_strategy'],\n",
    "#                                     selector_strategy=scen_config['selector'],\n",
    "#                                     survival_strategy=scen_config['survival'],\n",
    "#                                     n_elites=scen_config['n_elites'],\n",
    "#                                     log_level=0, verbose=0, **params\n",
    "#                                 )\n",
    "#                                 # Check if test_fitness exists\n",
    "#                                 if elite.test_fitness is not None:\n",
    "#                                     val_rmse = float(elite.test_fitness[0])\n",
    "#                                 else:\n",
    "#                                     val_rmse = float('inf')\n",
    "#                                 inner_rmse_scores.append(val_rmse)\n",
    "\n",
    "#                             except Exception as e:\n",
    "#                                 # IMPORTANTE: Agora vamos ver o erro real!\n",
    "#                                 print(f\"        [Inner Error] {e}\") \n",
    "#                                 inner_rmse_scores.append(float('inf'))\n",
    "                        \n",
    "#                         # Select Winner\n",
    "#                         median_rmse = np.median(inner_rmse_scores)\n",
    "#                         if median_rmse < best_inner_score:\n",
    "#                             best_inner_score = median_rmse\n",
    "#                             best_params = params.copy()\n",
    "#                             best_params['tournament_sizes'] = t_sizes\n",
    "\n",
    "#                     # --- PROTEÇÃO CONTRA CRASH ---\n",
    "#                     # Se todos os inner runs falharam, best_params continua None.\n",
    "#                     # Temos de saltar este cenário em vez de crashar.\n",
    "#                     if best_params is None:\n",
    "#                         print(f\"        [WARNING] All inner runs failed for {scen_name}. Skipping outer run.\")\n",
    "#                         continue \n",
    "\n",
    "#                     # 2. Final Training (Outer Fold)\n",
    "#                     fold_dir = f\"./log_mo/{ds_name}/{scen_name}/{obj_set_name}/fold_{outer_fold+1}\"\n",
    "#                     if not os.path.exists(fold_dir):\n",
    "#                         os.makedirs(fold_dir)\n",
    "                    \n",
    "#                     # Log Parameters\n",
    "#                     if 'tournament_sizes' in best_params: del best_params['tournament_sizes']\n",
    "#                     best_params['Median_Inner_RMSE'] = best_inner_score\n",
    "#                     pd.DataFrame([best_params]).to_csv(os.path.join(fold_dir, \"best_inner_params.csv\"), index=False)\n",
    "#                     print(f\"        > Best Params: {best_params} (RMSE Val: {best_inner_score:.4f})\")\n",
    "\n",
    "#                     # Run MOGP\n",
    "#                     log_path = os.path.join(fold_dir, \"execution_log.csv\")\n",
    "#                     t_sizes_final = [2] * n_objs\n",
    "                    \n",
    "#                     try:\n",
    "#                         mo_gp(\n",
    "#                             X_train=X_train_outer, y_train=y_train_outer,\n",
    "#                             X_test=X_test_outer, y_test=y_test_outer,\n",
    "#                             dataset_name=ds_name,\n",
    "#                             fitness_functions=obj_config['funcs'],\n",
    "#                             minimization_flags=obj_config['flags'],\n",
    "#                             tournament_sizes=t_sizes_final,\n",
    "#                             elitism_strategy=scen_config['elitism_strategy'],\n",
    "#                             selector_strategy=scen_config['selector'],\n",
    "#                             survival_strategy=scen_config['survival'],\n",
    "#                             n_elites=scen_config['n_elites'],\n",
    "#                             pop_size=best_params['pop_size'],\n",
    "#                             n_iter=best_params['n_iter'],\n",
    "#                             p_xo=best_params['p_xo'],\n",
    "#                             prob_const=best_params['prob_const'],\n",
    "#                             max_depth=best_params['max_depth'],\n",
    "#                             verbose=0, \n",
    "#                             log_level=5,\n",
    "#                             log_path=log_path,\n",
    "#                             n_jobs=1\n",
    "#                         )\n",
    "#                         print(f\"        > Log saved at: {log_path}\")\n",
    "                        \n",
    "#                     except Exception as e:\n",
    "#                         print(f\"      [Outer Error] {e}\")\n",
    "#                         import traceback\n",
    "#                         traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "Dataset: Toxicity\n",
      "========================================\n",
      "\n",
      "  > Outer Fold 1/15\n",
      "    > Objectives: 2_Objs\n",
      "      > Scenario: NSGA-II_Pure\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    for ds_name, loader_func in DATASETS.items():\n",
    "        print(f\"\\n{'='*40}\\nDataset: {ds_name}\\n{'='*40}\")\n",
    "    \n",
    "        # Load Data (X: features, y: target)\n",
    "        X, y = loader_func(X_y=True)\n",
    "    \n",
    "        # Outer CV (14 folds for train + 1 fold for test each time)\n",
    "        kf_outer = KFold(n_splits=K_OUTER, shuffle=True, random_state=RANDOM_SEED)\n",
    "    \n",
    "        for outer_fold, (train_idx, test_idx) in enumerate(kf_outer.split(X, y)):\n",
    "            print(f\"\\n  > Outer Fold {outer_fold+1}/{K_OUTER}\")\n",
    "        \n",
    "            X_train_outer = X[train_idx]\n",
    "            y_train_outer = y[train_idx]\n",
    "            X_test_outer = X[test_idx]\n",
    "            y_test_outer = y[test_idx]\n",
    "        \n",
    "            # Inner CV Setup\n",
    "            kf_inner = KFold(n_splits=K_INNER, shuffle=True, random_state=RANDOM_SEED)\n",
    "        \n",
    "            for obj_set_name, obj_config in OBJECTIVE_SETS.items():\n",
    "                n_objs = len(obj_config['funcs'])\n",
    "                print(f\"    > Objectives: {obj_set_name}\")\n",
    "            \n",
    "                for scen_name, scen_config in SCENARIOS.items():\n",
    "                    print(f\"      > Scenario: {scen_name}\")\n",
    "                \n",
    "                    # Hyperparameter Tuning (Inner CV)\n",
    "                    best_params = None\n",
    "                    best_inner_score = float('inf') # Min RMSE of validation\n",
    "                \n",
    "                    # All possible parameter configurations\n",
    "                    current_grid = list(ParameterGrid(PARAM_GRID))\n",
    "                \n",
    "                    for params in current_grid:\n",
    "                        # tournament sizes probably has a big impact but let's leave it constant for now\n",
    "                        t_sizes = [2] * n_objs\n",
    "\n",
    "                        inner_rmse_scores = []\n",
    "\n",
    "                        # Loop Inner CV: trains in (k_inner -1) folds, validates in 1 fold\n",
    "                        for inner_t_idx, inner_v_idx in kf_inner.split(X_train_outer, y_train_outer):\n",
    "                            X_in_t, y_in_t = X_train_outer[inner_t_idx], y_train_outer[inner_t_idx]\n",
    "                            X_in_v, y_in_v = X_train_outer[inner_v_idx], y_train_outer[inner_v_idx]\n",
    "                        \n",
    "                            # Run MOGP (I suppress output for inner loops)\n",
    "                            try:\n",
    "                                elite = mo_gp(\n",
    "                                    X_train=X_in_t, y_train=y_in_t,\n",
    "                                    X_test=X_in_v, y_test=y_in_v,\n",
    "                                    dataset_name=f\"{ds_name}_inner\",\n",
    "                                    fitness_functions=obj_config['funcs'],\n",
    "                                    minimization_flags=obj_config['flags'],\n",
    "                                    tournament_sizes=t_sizes,\n",
    "                                    elitism_strategy=scen_config['elitism_strategy'],\n",
    "                                    selector_strategy=scen_config['selector'],\n",
    "                                    survival_strategy=scen_config['survival'],\n",
    "                                    n_elites=scen_config['n_elites'],\n",
    "                                    log_level=0, verbose=0, **params # No logging for inner\n",
    "                                )\n",
    "                                # validation RMSE:find_mo_elites_default returns elite with test_fitness already calculated  \n",
    "                                if elite.test_fitness is not None:\n",
    "                                    val_rmse = float(elite.test_fitness[0])\n",
    "                                else:\n",
    "                                    val_rmse = float('inf')\n",
    "                                inner_rmse_scores.append(val_rmse)\n",
    "\n",
    "                            except Exception as e:\n",
    "                                # ############# APAGAR\n",
    "                                # print(f\"        [Inner Error] {e}\") \n",
    "                                # import traceback\n",
    "                                # traceback.print_exc()\n",
    "                                # #############\n",
    "                                # for debug\n",
    "                                inner_rmse_scores.append(float('inf'))\n",
    "                    \n",
    "                        # The winner is the one with the lowest median RMSE in validation\n",
    "                        median_rmse = np.median(inner_rmse_scores)\n",
    "                    \n",
    "                        if median_rmse < best_inner_score:\n",
    "                            best_inner_score = median_rmse\n",
    "                            best_params = params.copy()\n",
    "                            best_params['tournament_sizes'] = t_sizes   # Store the calculated list \n",
    "\n",
    "                    # #########DEBUG######### APAGAR\n",
    "                    # if best_params is None:\n",
    "                    #     print(f\"        [WARNING] All inner runs failed for {scen_name}. Skipping outer run.\")\n",
    "                    #     continue\n",
    "                    # #######################\n",
    "\n",
    "                    # Setup Log Directory: ./log_mo / Dataset / Scenario / Objetivos / fold_X /\n",
    "                    fold_dir = f\"./log_mo/{ds_name}/{scen_name}/{obj_set_name}/fold_{outer_fold+1}\"\n",
    "                    if not os.path.exists(fold_dir):\n",
    "                        os.makedirs(fold_dir)\n",
    "                \n",
    "                    # Save CSV of Winner Hyperparameters\n",
    "                    # remove tournament_sizes from csv to make it cleaner\n",
    "                    if 'tournament_sizes' in best_params: del best_params['tournament_sizes'] \n",
    "                \n",
    "                    #just to have the inner score saved\n",
    "                    best_params['Median_Inner_RMSE'] = best_inner_score\n",
    "\n",
    "                    pd.DataFrame([best_params]).to_csv(os.path.join(fold_dir, \"best_inner_params.csv\"), index=False)\n",
    "                \n",
    "                    print(f\"        > Best Params: {best_params} (RMSE Val: {best_inner_score:.4f})\")\n",
    "\n",
    "                    # final training with best hyperparameters on the outer fold\n",
    "                    log_path = os.path.join(fold_dir, \"execution_log.csv\")\n",
    "\n",
    "                    t_sizes_final = [2] * n_objs #needs to be recalculated here again because I dropped it before\n",
    "                \n",
    "                    try:\n",
    "                        mo_gp(\n",
    "                            X_train=X_train_outer, y_train=y_train_outer,\n",
    "                            X_test=X_test_outer, y_test=y_test_outer,\n",
    "                            dataset_name=ds_name,\n",
    "                            fitness_functions=obj_config['funcs'],\n",
    "                            minimization_flags=obj_config['flags'],\n",
    "                            tournament_sizes=t_sizes_final,\n",
    "                            elitism_strategy=scen_config['elitism_strategy'],\n",
    "                            selector_strategy=scen_config['selector'],\n",
    "                            survival_strategy=scen_config['survival'],\n",
    "                            n_elites=scen_config['n_elites'],\n",
    "                            # use winner params found\n",
    "                            pop_size=best_params['pop_size'],\n",
    "                            n_iter=best_params['n_iter'],\n",
    "                            p_xo=best_params['p_xo'],\n",
    "                            prob_const=best_params['prob_const'],\n",
    "                            max_depth=best_params['max_depth'],\n",
    "                            verbose=0, \n",
    "                            log_level=5,\n",
    "                            log_path=log_path,\n",
    "                            n_jobs=1\n",
    "                        )\n",
    "                        print(f\"        > Log saved at: {log_path}\")\n",
    "                    \n",
    "                    except Exception as e:\n",
    "                        print(f\"      [Outer Error] {e}\")\n",
    "                        import traceback\n",
    "                        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import scipy.stats as sp\n",
    "import scikit_posthocs as sp_post\n",
    "\n",
    "# configuration\n",
    "LOG_DIR = './log_mo'       # where logs are stored\n",
    "OUTPUT_DIR = './plots_mo'  #where I'll save the plots\n",
    "\n",
    "COLORS = {\n",
    "    'Train_RMSE': '#1f77b4',\n",
    "    'Test_RMSE': '#ff7f0e',\n",
    "    'Std_Dev': '#9467bd',\n",
    "    'Size': '#2ca02c',\n",
    "    'Features': '#d62728',\n",
    "    'NAO': '#17becf',\n",
    "    'NAOC': '#e377c2'\n",
    "}\n",
    "\n",
    "OBJ_MAP = {\n",
    "    0: \"RMSE\",\n",
    "    1: \"Size\",\n",
    "    2: \"Features\",\n",
    "    3: \"NAO\",\n",
    "    4: \"NAOC\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforms a column with \"5.1|10.2\" strings into a DataFrame of floats\n",
    "def parse_fitness_column(series, log_file_name=\"Unknown\", allow_na=False):\n",
    "    # deal with NaN values first\n",
    "    if series.isna().any():\n",
    "        if allow_na:\n",
    "            # if it is allowed, return None\n",
    "            return None\n",
    "        else:\n",
    "            # if it is mandatory (like RMSE), NaN is a critical error\n",
    "            raise ValueError(\n",
    "                f\"[CRITICAL ERROR] Found NaN in mandatory column in file '{log_file_name}'. \"\n",
    "                \"This means the Elite was not evaluated correctly.\"\n",
    "            )\n",
    "\n",
    "    # Convert to string for uniform processing\n",
    "    series_str = series.astype(str)\n",
    "\n",
    "    # Handle the literal string \"N/A\" (in case pandas did not convert it to NaN)\n",
    "    if (series_str == \"N/A\").any():\n",
    "        if allow_na:\n",
    "            return None\n",
    "        else:\n",
    "            error_idx = series_str[series_str == \"N/A\"].index[0]\n",
    "            raise ValueError(\n",
    "                f\"[CRITICAL ERROR] Found 'N/A' string in file '{log_file_name}' at line {error_idx}.\"\n",
    "            )\n",
    "\n",
    "    # try to split and convert to float\n",
    "    try:\n",
    "        return series_str.str.split('|', expand=True).astype(float)\n",
    "    except ValueError as e:\n",
    "        raise ValueError(f\"[CRITICAL] Could not convert fitness to numbers in {log_file_name}. Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load data from all logs\n",
    "def load_data_for_analysis(dataset_name, objectives_key, view_mode='main'):\n",
    "    target_path = os.path.join(LOG_DIR, dataset_name)\n",
    "    \n",
    "    if not os.path.exists(target_path):\n",
    "        print(f\"[ERROR] Folder not found: {target_path}\")\n",
    "        return None, None\n",
    "\n",
    "    # Find all scenarios\n",
    "    scenarios = [d for d in os.listdir(target_path) if os.path.isdir(os.path.join(target_path, d))]\n",
    "    \n",
    "    history_data = {} \n",
    "    final_rows = []   \n",
    "\n",
    "    print(f\"Logs from {dataset_name} ({objectives_key}) - View: {view_mode.upper()}\")\n",
    "\n",
    "    for scen in scenarios:\n",
    "        pattern = os.path.join(target_path, scen, objectives_key, \"fold_*\", \"execution_log.csv\")\n",
    "        files = glob.glob(pattern)\n",
    "        \n",
    "        if not files: continue\n",
    "        \n",
    "        history_data[scen] = []\n",
    "        \n",
    "        for f in files:\n",
    "            try:\n",
    "                df = pd.read_csv(f)\n",
    "                \n",
    "                # --- INDEX MAPPING (Based on MOGP Logger) ---                \n",
    "                # 0: Algo, 1: UUID, 2: Dataset, 3: Seed\n",
    "                # 4: Gen, 5: Main Train Fit, 6: Time, 7: Main Nodes\n",
    "                # 8: Main Test Fit, 9: RMSE Elite Test Fit, 10: RMSE Elite Nodes\n",
    "                # 11: Std Dev, 12: Ideal Point\n",
    "\n",
    "                idx_offset = 4 \n",
    "                \n",
    "                gen_idx = 0 + idx_offset  # 4\n",
    "                std_idx = 7 + idx_offset  # 11\n",
    "                ideal_idx = 8 + idx_offset # 12               \n",
    "\n",
    "                if view_mode == 'rmse':\n",
    "                    # RMSE View: Main Train and RMSE Elite Test\n",
    "                    train_idx = 1 + idx_offset \n",
    "                    test_idx = 5 + idx_offset\n",
    "                    size_idx = 6 + idx_offset\n",
    "                else:\n",
    "                    # Main View: Main Train + Main Test\n",
    "                    train_idx = 1 + idx_offset\n",
    "                    test_idx = 4 + idx_offset\n",
    "                    size_idx = 3 + idx_offset\n",
    "                \n",
    "                # Parse Fitness Columns    \n",
    "                train_fits = parse_fitness_column(df.iloc[:, train_idx], f, allow_na=False)\n",
    "                test_fits = parse_fitness_column(df.iloc[:, test_idx], f, allow_na=False)\n",
    "                \n",
    "                # Ideal Point (allow_na=True because it is N/A for most scenarios)\n",
    "                ideal_fits = parse_fitness_column(df.iloc[:, ideal_idx], f, allow_na=True)\n",
    "\n",
    "                # Clean DataFrame\n",
    "                clean_df = pd.DataFrame({\n",
    "                    'Generation': df.iloc[:, gen_idx],\n",
    "                    'Std_RMSE': df.iloc[:, std_idx]\n",
    "                })\n",
    "                \n",
    "                # Add Train Metrics\n",
    "                if train_fits is not None:\n",
    "                    for c in train_fits.columns:\n",
    "                        clean_df[f'Train_{OBJ_MAP.get(c, c)}'] = train_fits[c]\n",
    "                \n",
    "                # Add Test Metrics\n",
    "                if test_fits is not None:\n",
    "                    for c in test_fits.columns:\n",
    "                        clean_df[f'Test_{OBJ_MAP.get(c, c)}'] = test_fits[c]\n",
    "                \n",
    "                clean_df['Test_Size'] = df.iloc[:, size_idx]\n",
    "                \n",
    "                # Add Ideal Point if available\n",
    "                if ideal_fits is not None:\n",
    "                    clean_df['Ideal_RMSE'] = ideal_fits[0]\n",
    "\n",
    "                history_data[scen].append(clean_df)\n",
    "                \n",
    "                # Data for Boxplots (Last Generation)\n",
    "                last_row = clean_df.iloc[-1]\n",
    "                try: fold_num = int(f.split(os.sep)[-2].split('_')[-1])\n",
    "                except: fold_num = 0\n",
    "\n",
    "                row_dict = {'Dataset': dataset_name, 'Scenario': scen, 'Fold': fold_num}\n",
    "                for col in clean_df.columns:\n",
    "                    if col.startswith('Train_') or col.startswith('Test_'):\n",
    "                        row_dict[col] = last_row[col]\n",
    "                final_rows.append(row_dict)\n",
    "            except Exception as e:\n",
    "                print(f\"  [WARN] Could not process file {f}: {e}\")\n",
    "\n",
    "    final_df = pd.DataFrame(final_rows)\n",
    "    return history_data, final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_convergence(dataset_name, objectives_key, history_data, view_mode):\n",
    "    save_dir = os.path.join(OUTPUT_DIR, dataset_name, objectives_key)\n",
    "    if not os.path.exists(save_dir): os.makedirs(save_dir)\n",
    "\n",
    "    for scen, folds_list in history_data.items():\n",
    "        if not folds_list: continue\n",
    "\n",
    "        sample_df = folds_list[0]\n",
    "        metrics = [c.replace(\"Test_\", \"\") for c in sample_df.columns if c.startswith(\"Test_\")]\n",
    "        min_len = min([len(df) for df in folds_list])\n",
    "        generations = np.arange(min_len)\n",
    "\n",
    "        fig = make_subplots(\n",
    "            rows=1, cols=3,\n",
    "            subplot_titles=(\"Performance (RMSE)\", \"Structural Complexity\", \"Pop RMSE Std Dev\"),\n",
    "            horizontal_spacing=0.08\n",
    "        )\n",
    "\n",
    "        def add_trace(col, name, color, idx, show_leg=True):\n",
    "            if col not in sample_df.columns: return\n",
    "\n",
    "            data = np.array([df[col].values[:min_len] for df in folds_list])\n",
    "            median = np.median(data, axis=0)\n",
    "            q1 = np.percentile(data, 15, axis=0)\n",
    "            q3 = np.percentile(data, 85, axis=0)\n",
    "\n",
    "            # IQR shading\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=np.concatenate([generations, generations[::-1]]),\n",
    "                y=np.concatenate([q3, q1[::-1]]),\n",
    "                fill='toself', fillcolor=color, opacity=0.15,\n",
    "                line=dict(width=0), showlegend=False), row=1, col=idx)\n",
    "\n",
    "            # Median Line\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=generations, y=median, mode='lines', name=name,\n",
    "                line=dict(color=color)), row=1, col=idx)\n",
    "\n",
    "        # Plot 1: Performance\n",
    "        add_trace('Train_RMSE', 'Train RMSE', COLORS['Train_RMSE'], 1)\n",
    "        add_trace('Test_RMSE', 'Test RMSE', COLORS['Test_RMSE'], 1)\n",
    "        \n",
    "        # Add Ideal Point line if it exists\n",
    "        if 'Ideal_RMSE' in sample_df.columns:\n",
    "             add_trace('Ideal_RMSE', 'Ideal Point', 'black', 1, show_leg=True)\n",
    "\n",
    "        # Plot 2: Complexity\n",
    "        add_trace('Test_Size', 'Size', COLORS['Size'], 2)\n",
    "        for metric in [m for m in metrics if m != \"RMSE\" and m != \"Size\"]:\n",
    "            color = COLORS.get(metric, '#333333')\n",
    "            add_trace(f'Test_{metric}', metric, color, 2)\n",
    "\n",
    "        # Plot 3: Std Dev\n",
    "        add_trace('Std_RMSE', 'RMSE Std Dev', COLORS['Std_Dev'], 3, show_leg=False)\n",
    "\n",
    "        fig.update_layout(\n",
    "            title=f\"Convergence Analysis: {scen} ({dataset_name} | {objectives_key} | {view_mode.upper()})\",\n",
    "            height=500, width=1400, template=\"plotly_white\",\n",
    "            legend=dict(orientation=\"h\", y=-0.15, x=0.5, xanchor=\"center\")\n",
    "        )\n",
    "        \n",
    "        file_path = os.path.join(save_dir, f\"convergence_{scen}_VIEW_{view_mode.upper()}.png\")\n",
    "        fig.write_image(file_path)\n",
    "        print(f\"  -> Saved convergence: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_boxplots(dataset_name, objectives_key, final_df, view_mode):\n",
    "    save_dir = os.path.join(OUTPUT_DIR, dataset_name, objectives_key)\n",
    "    \n",
    "    if final_df.empty: return\n",
    "\n",
    "    df_melt = final_df.melt(\n",
    "        id_vars=['Scenario'], \n",
    "        value_vars=['Train_RMSE', 'Test_RMSE'],\n",
    "        var_name='Type', value_name='RMSE'\n",
    "    )\n",
    "    \n",
    "    plt.figure(figsize=(12, 7))\n",
    "    sns.set_style(\"whitegrid\")\n",
    "\n",
    "    sns.boxplot(\n",
    "        data=df_melt, x='Scenario', y='RMSE', hue='Type',\n",
    "        palette=[COLORS['Train_RMSE'], COLORS['Test_RMSE']],\n",
    "        width=0.6, linewidth=1.2, showfliers=False \n",
    "    )\n",
    "    sns.stripplot(\n",
    "        data=df_melt, x='Scenario', y='RMSE', hue='Type',\n",
    "        dodge=True, color='black', alpha=0.3, size=3, legend=False\n",
    "    )\n",
    "\n",
    "    plt.title(f'Final RMSE Distribution: {dataset_name} ({view_mode.upper()})', fontsize=14)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    filename = f\"boxplot_rmse_VIEW_{view_mode.upper()}.png\"\n",
    "    plt.savefig(os.path.join(save_dir, filename), dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"  -> Saved RMSE boxplot.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_stats(dataset_name, objectives_key, final_df, view_mode, save_dir):\n",
    "    if final_df.empty: return\n",
    "    \n",
    "    try:\n",
    "        pivot_df = final_df.pivot(index='Fold', columns='Scenario', values='Test_RMSE')\n",
    "        \n",
    "        output_txt = [f\"=== Stats: {dataset_name} ({objectives_key}) ===\\n\"]\n",
    "        output_txt.append(pivot_df.describe().to_string() + \"\\n\\n\")\n",
    "        \n",
    "        stat, p = sp.friedmanchisquare(*[pivot_df[col] for col in pivot_df.columns])\n",
    "        output_txt.append(f\"Friedman Test:\\nStatistic: {stat:.4f}, p-value: {p:.6f}\\n\")\n",
    "        \n",
    "        if p < 0.05:\n",
    "            output_txt.append(\"\\nSignificant differences found. Nemenyi Post-Hoc:\\n\")\n",
    "            nemenyi = sp_post.posthoc_nemenyi_friedman(pivot_df)\n",
    "            output_txt.append(nemenyi.to_string())\n",
    "        \n",
    "        filename = f\"stats_VIEW_{view_mode.upper()}.txt\"\n",
    "        with open(os.path.join(save_dir, filename), \"w\") as f:\n",
    "            f.write(\"\".join(output_txt))\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Stats Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import KFold, ParameterGrid\n",
    "from slim_gsgp.main_mo_gp import mo_gp\n",
    "from slim_gsgp.datasets.data_loader import (\n",
    "     load_efficiency_cooling, load_ld50\n",
    ")\n",
    "DATASETS = {\n",
    "    #'Cooling': load_efficiency_cooling,\n",
    "    'Toxicity': load_ld50,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing Toxicity [2_Objs] ---\n",
      "Logs from Toxicity (2_Objs) - View: MAIN\n",
      "  -> Saved convergence: ./plots_mo\\Toxicity\\2_Objs\\convergence_NSGA-II_Pure_VIEW_MAIN.png\n",
      "  -> Saved convergence: ./plots_mo\\Toxicity\\2_Objs\\convergence_NT_1st_Obj_Elitism_VIEW_MAIN.png\n",
      "  -> Saved convergence: ./plots_mo\\Toxicity\\2_Objs\\convergence_NT_Ideal_Cand_Elitism_VIEW_MAIN.png\n",
      "  -> Saved convergence: ./plots_mo\\Toxicity\\2_Objs\\convergence_NT_No_Elitism_VIEW_MAIN.png\n",
      "  -> Saved convergence: ./plots_mo\\Toxicity\\2_Objs\\convergence_NT_NSGA-II_VIEW_MAIN.png\n",
      "  -> Saved convergence: ./plots_mo\\Toxicity\\2_Objs\\convergence_NT_Rank_CD_Elitism_VIEW_MAIN.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\filip\\AppData\\Local\\Temp\\ipykernel_2488\\3295342174.py:20: FutureWarning:\n",
      "\n",
      "\n",
      "\n",
      "Setting a gradient palette using color= is deprecated and will be removed in v0.14.0. Set `palette='dark:black'` for the same effect.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Saved RMSE boxplot.\n",
      "\n",
      "--- Processing Toxicity [2_Objs] ---\n",
      "Logs from Toxicity (2_Objs) - View: RMSE\n",
      "  -> Saved convergence: ./plots_mo\\Toxicity\\2_Objs\\convergence_NSGA-II_Pure_VIEW_RMSE.png\n",
      "  -> Saved convergence: ./plots_mo\\Toxicity\\2_Objs\\convergence_NT_1st_Obj_Elitism_VIEW_RMSE.png\n",
      "  -> Saved convergence: ./plots_mo\\Toxicity\\2_Objs\\convergence_NT_Ideal_Cand_Elitism_VIEW_RMSE.png\n",
      "  -> Saved convergence: ./plots_mo\\Toxicity\\2_Objs\\convergence_NT_No_Elitism_VIEW_RMSE.png\n",
      "  -> Saved convergence: ./plots_mo\\Toxicity\\2_Objs\\convergence_NT_NSGA-II_VIEW_RMSE.png\n",
      "  -> Saved convergence: ./plots_mo\\Toxicity\\2_Objs\\convergence_NT_Rank_CD_Elitism_VIEW_RMSE.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\filip\\AppData\\Local\\Temp\\ipykernel_2488\\3295342174.py:20: FutureWarning:\n",
      "\n",
      "\n",
      "\n",
      "Setting a gradient palette using color= is deprecated and will be removed in v0.14.0. Set `palette='dark:black'` for the same effect.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Saved RMSE boxplot.\n",
      "\n",
      "--- Processing Toxicity [3_Objs] ---\n",
      "Logs from Toxicity (3_Objs) - View: MAIN\n",
      "  -> Saved convergence: ./plots_mo\\Toxicity\\3_Objs\\convergence_NSGA-II_Pure_VIEW_MAIN.png\n",
      "  -> Saved convergence: ./plots_mo\\Toxicity\\3_Objs\\convergence_NT_1st_Obj_Elitism_VIEW_MAIN.png\n",
      "  -> Saved convergence: ./plots_mo\\Toxicity\\3_Objs\\convergence_NT_Ideal_Cand_Elitism_VIEW_MAIN.png\n",
      "  -> Saved convergence: ./plots_mo\\Toxicity\\3_Objs\\convergence_NT_No_Elitism_VIEW_MAIN.png\n",
      "  -> Saved convergence: ./plots_mo\\Toxicity\\3_Objs\\convergence_NT_NSGA-II_VIEW_MAIN.png\n",
      "  -> Saved convergence: ./plots_mo\\Toxicity\\3_Objs\\convergence_NT_Rank_CD_Elitism_VIEW_MAIN.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\filip\\AppData\\Local\\Temp\\ipykernel_2488\\3295342174.py:20: FutureWarning:\n",
      "\n",
      "\n",
      "\n",
      "Setting a gradient palette using color= is deprecated and will be removed in v0.14.0. Set `palette='dark:black'` for the same effect.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Saved RMSE boxplot.\n",
      "\n",
      "--- Processing Toxicity [3_Objs] ---\n",
      "Logs from Toxicity (3_Objs) - View: RMSE\n",
      "  -> Saved convergence: ./plots_mo\\Toxicity\\3_Objs\\convergence_NSGA-II_Pure_VIEW_RMSE.png\n",
      "  -> Saved convergence: ./plots_mo\\Toxicity\\3_Objs\\convergence_NT_1st_Obj_Elitism_VIEW_RMSE.png\n",
      "  -> Saved convergence: ./plots_mo\\Toxicity\\3_Objs\\convergence_NT_Ideal_Cand_Elitism_VIEW_RMSE.png\n",
      "  -> Saved convergence: ./plots_mo\\Toxicity\\3_Objs\\convergence_NT_No_Elitism_VIEW_RMSE.png\n",
      "  -> Saved convergence: ./plots_mo\\Toxicity\\3_Objs\\convergence_NT_NSGA-II_VIEW_RMSE.png\n",
      "  -> Saved convergence: ./plots_mo\\Toxicity\\3_Objs\\convergence_NT_Rank_CD_Elitism_VIEW_RMSE.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\filip\\AppData\\Local\\Temp\\ipykernel_2488\\3295342174.py:20: FutureWarning:\n",
      "\n",
      "\n",
      "\n",
      "Setting a gradient palette using color= is deprecated and will be removed in v0.14.0. Set `palette='dark:black'` for the same effect.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Saved RMSE boxplot.\n",
      "\n",
      "--- Processing Toxicity [5_Objs] ---\n",
      "Logs from Toxicity (5_Objs) - View: MAIN\n",
      "  -> Saved convergence: ./plots_mo\\Toxicity\\5_Objs\\convergence_NSGA-II_Pure_VIEW_MAIN.png\n",
      "  -> Saved convergence: ./plots_mo\\Toxicity\\5_Objs\\convergence_NT_1st_Obj_Elitism_VIEW_MAIN.png\n",
      "  -> Saved convergence: ./plots_mo\\Toxicity\\5_Objs\\convergence_NT_Ideal_Cand_Elitism_VIEW_MAIN.png\n",
      "  -> Saved convergence: ./plots_mo\\Toxicity\\5_Objs\\convergence_NT_No_Elitism_VIEW_MAIN.png\n",
      "  -> Saved convergence: ./plots_mo\\Toxicity\\5_Objs\\convergence_NT_NSGA-II_VIEW_MAIN.png\n",
      "  -> Saved convergence: ./plots_mo\\Toxicity\\5_Objs\\convergence_NT_Rank_CD_Elitism_VIEW_MAIN.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\filip\\AppData\\Local\\Temp\\ipykernel_2488\\3295342174.py:20: FutureWarning:\n",
      "\n",
      "\n",
      "\n",
      "Setting a gradient palette using color= is deprecated and will be removed in v0.14.0. Set `palette='dark:black'` for the same effect.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Saved RMSE boxplot.\n",
      "\n",
      "--- Processing Toxicity [5_Objs] ---\n",
      "Logs from Toxicity (5_Objs) - View: RMSE\n",
      "  -> Saved convergence: ./plots_mo\\Toxicity\\5_Objs\\convergence_NSGA-II_Pure_VIEW_RMSE.png\n",
      "  -> Saved convergence: ./plots_mo\\Toxicity\\5_Objs\\convergence_NT_1st_Obj_Elitism_VIEW_RMSE.png\n",
      "  -> Saved convergence: ./plots_mo\\Toxicity\\5_Objs\\convergence_NT_Ideal_Cand_Elitism_VIEW_RMSE.png\n",
      "  -> Saved convergence: ./plots_mo\\Toxicity\\5_Objs\\convergence_NT_No_Elitism_VIEW_RMSE.png\n",
      "  -> Saved convergence: ./plots_mo\\Toxicity\\5_Objs\\convergence_NT_NSGA-II_VIEW_RMSE.png\n",
      "  -> Saved convergence: ./plots_mo\\Toxicity\\5_Objs\\convergence_NT_Rank_CD_Elitism_VIEW_RMSE.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\filip\\AppData\\Local\\Temp\\ipykernel_2488\\3295342174.py:20: FutureWarning:\n",
      "\n",
      "\n",
      "\n",
      "Setting a gradient palette using color= is deprecated and will be removed in v0.14.0. Set `palette='dark:black'` for the same effect.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Saved RMSE boxplot.\n"
     ]
    }
   ],
   "source": [
    "def generate_all_plots(dataset_name, objectives_key='2_Objs', view_mode='main'):\n",
    "    print(f\"\\n--- Processing {dataset_name} [{objectives_key}] ---\")\n",
    "    \n",
    "    history_data, final_df = load_data_for_analysis(dataset_name, objectives_key, view_mode)\n",
    "    \n",
    "    if final_df is None or final_df.empty:\n",
    "        print(\"No data found.\")\n",
    "        return\n",
    "\n",
    "    plot_convergence(dataset_name, objectives_key, history_data, view_mode)\n",
    "    plot_boxplots(dataset_name, objectives_key, final_df, view_mode)\n",
    "    \n",
    "    save_dir = os.path.join(OUTPUT_DIR, dataset_name, objectives_key)\n",
    "    run_stats(dataset_name, objectives_key, final_df, view_mode, save_dir)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    for ds in DATASETS: # DATASETS dict defined in run_experiments, or hardcode list here\n",
    "        for obj in ['2_Objs', '3_Objs', '5_Objs']:\n",
    "            for mode in ['main', 'rmse']:\n",
    "                generate_all_plots(ds, obj, mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function goes through the log folders and loads the raw data from all scenarios and folds\n",
    "#It returns:\n",
    "# 1. history_data: Dictionary with generation-by-generation evolution (for Convergence Plots) considering the view_mode \n",
    "# 2. final_data: DataFrame with the last generation of each fold (for Boxplots and Stats)\n",
    "def load_data_for_analysis(dataset_name, objectives_key, view_mode='main'):\n",
    "\n",
    "    target_path = os.path.join(LOG_DIR, dataset_name)\n",
    "    \n",
    "    if not os.path.exists(target_path):\n",
    "        print(f\"[ERROR] Folder not found: {target_path}\")\n",
    "        return None, None\n",
    "\n",
    "    # Find all scenarios (Traditional NSGA-II, NT+NSGA-II, ...)\n",
    "    scenarios = [d for d in os.listdir(target_path) if os.path.isdir(os.path.join(target_path, d))]\n",
    "    \n",
    "    history_data = {} #{scenario: [list of DataFrames per fold]}\n",
    "    final_rows = []   #list of dicts for final DataFrame\n",
    "\n",
    "    print(f\"Logs from {dataset_name} dataset with these objectives: {objectives_key} considering the view mode {view_mode.upper()}\")\n",
    "\n",
    "    for scen in scenarios:\n",
    "        # Path: ./log_mo/Dataset/Scenario/Objetives/fold_*/execution_log.csv\n",
    "        pattern = os.path.join(target_path, scen, objectives_key, \"fold_*\", \"execution_log.csv\")\n",
    "        files = glob.glob(pattern)\n",
    "        \n",
    "        if not files:\n",
    "            continue\n",
    "            \n",
    "        history_data[scen] = []\n",
    "        \n",
    "        for f in files:\n",
    "            try:\n",
    "                df = pd.read_csv(f)\n",
    "                # 0: Gen, 1: Main Train, 2: Time, 3: Main Nodes\n",
    "                # 4: Main Test, 5: RMSE Elite Test, 6: RMSE Elite Nodes\n",
    "                # 7: Std Dev, 8: Ideal Point\n",
    "                \n",
    "                # Depends on which metrics should we look at to find the best individual\n",
    "                if view_mode == 'rmse':\n",
    "                    train_idx = 1 \n",
    "                    test_idx = 5\n",
    "                    size_idx = 6 # RMSE Elite Size \n",
    "                else:\n",
    "                    # 'main' view mode\n",
    "                    train_idx = 1\n",
    "                    test_idx = 4\n",
    "                    size_idx = 3 # Main Elite Size\n",
    "                \n",
    "                # Parsing fitness columns ( allow_na=True for Ideal Point)\n",
    "                train_fits = parse_fitness_column(df.iloc[:, train_idx], f, allow_na=False)\n",
    "                test_fits = parse_fitness_column(df.iloc[:, test_idx], f, allow_na=False)\n",
    "                \n",
    "                ideal_fits = parse_fitness_column(df.iloc[:, 8], f, allow_na=True)\n",
    "\n",
    "                # get a clean DataFrame with relevant info to plot\n",
    "                clean_df = pd.DataFrame({\n",
    "                    'Generation': df.iloc[:, 0],\n",
    "                    'Std_RMSE': df.iloc[:, 7]\n",
    "                })\n",
    "                \n",
    "                # add train metrics dynamically (could be RMSE, Size, Features...)\n",
    "                if train_fits is not None:\n",
    "                    for c in train_fits.columns:\n",
    "                        clean_df[f'Train_{OBJ_MAP.get(c, c)}'] = train_fits[c]\n",
    "                if test_fits is not None:\n",
    "                    for c in test_fits.columns:\n",
    "                        clean_df[f'Test_{OBJ_MAP.get(c, c)}'] = test_fits[c]\n",
    "                \n",
    "                clean_df['Test_Size'] = df.iloc[:, size_idx]\n",
    "                # we only add Ideal_RMSE if available\n",
    "                if ideal_fits is not None:\n",
    "                    clean_df['Ideal_RMSE'] = ideal_fits[0]\n",
    "\n",
    "                history_data[scen].append(clean_df)\n",
    "                \n",
    "                # last generation for boxplots\n",
    "                last_row = clean_df.iloc[-1]\n",
    "                try: fold_num = int(f.split(os.sep)[-2].split('_')[-1])\n",
    "                except: fold_num = 0\n",
    "\n",
    "                row_dict = {'Dataset': dataset_name, 'Scenario': scen, 'Fold': fold_num}\n",
    "                for col in clean_df.columns:\n",
    "                    if col.startswith('Train_') or col.startswith('Test_'):\n",
    "                        row_dict[col] = last_row[col]\n",
    "                final_rows.append(row_dict)\n",
    "            except Exception as e:\n",
    "                print(f\"  [WARN] Could not process file {f}: {e}\")\n",
    "\n",
    "    final_df = pd.DataFrame(final_rows)\n",
    "    return history_data, final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "#APAGAR#\n",
    "####################\n",
    "#COMO VAI USAR ISTO? AS ALTERAÇÕES QUE ISTO PROVOCOU NÃO ALTEROU OS INDEXES?\n",
    "                #ideal_str,        # Ideal Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_convergence(dataset_name, objectives_key, history_data, view_mode):\n",
    "    save_dir = os.path.join(OUTPUT_DIR, dataset_name, objectives_key)\n",
    "    if not os.path.exists(save_dir): os.makedirs(save_dir)\n",
    "\n",
    "    for scen, folds_list in history_data.items():\n",
    "        if not folds_list: continue\n",
    "\n",
    "        # get metrics starting with \"Test_\"\n",
    "        sample_df = folds_list[0]\n",
    "        # Ex: [\"RMSE\", \"Size\", \"Features\"]\n",
    "        metrics = [c.replace(\"Test_\", \"\") for c in sample_df.columns if c.startswith(\"Test_\")]\n",
    "        \n",
    "        min_len = min([len(df) for df in folds_list])\n",
    "        generations = np.arange(min_len)\n",
    "\n",
    "        fig = make_subplots(\n",
    "            rows=1, cols=3,\n",
    "            subplot_titles=(\"Performance (RMSE)\", \"Structural Complexity\", \"Pop RMSE Std Dev\"),\n",
    "            horizontal_spacing=0.08\n",
    "        )\n",
    "\n",
    "        # Helper function to draw traces: median line + IQR shading\n",
    "        def add_trace(col, name, color, idx, show_leg=True):\n",
    "            if col not in sample_df.columns: return\n",
    "\n",
    "            data = np.array([df[col].values[:min_len] for df in folds_list])\n",
    "            median = np.median(data, axis=0)\n",
    "            q1 = np.percentile(data, 15, axis=0)\n",
    "            q3 = np.percentile(data, 85, axis=0)\n",
    "\n",
    "            # IQR shading\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=np.concatenate([generations, generations[::-1]]),\n",
    "                y=np.concatenate([q3, q1[::-1]]),\n",
    "                fill='toself', fillcolor=color, opacity=0.15,\n",
    "                line=dict(width=0), showlegend=False), row=1, col=idx)\n",
    "\n",
    "            # Median\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=generations, y=median, mode='lines', name=name,\n",
    "                line=dict(color=color)), row=1, col=idx)\n",
    "\n",
    "        # PLOT 1: RMSE (Train vs Test)\n",
    "        add_trace('Train_RMSE', 'Train RMSE', COLORS['Train_RMSE'], 1)\n",
    "        add_trace('Test_RMSE', 'Test RMSE', COLORS['Test_RMSE'], 1)\n",
    "        add_trace('Test_Size', 'Size', COLORS['Size'], 2)\n",
    "        add_trace('Std_RMSE', 'Std Dev', COLORS['Std_Dev'], 3, show_leg=False)\n",
    "\n",
    "        # PLOT 2: COMPLEXITY (Size, Features, etc.): we use only TEST data cause the structure is the same\n",
    "        for metric in [m for m in metrics if m != \"RMSE\"]:\n",
    "            color = COLORS.get(metric, '#333333')\n",
    "            add_trace(f'Test_{metric}', metric, color, 2)\n",
    "\n",
    "        # PLOT 3: STD DEV\n",
    "        if 'Std_RMSE' in sample_df.columns:\n",
    "            add_trace('Std_RMSE', 'RMSE Std Dev', COLORS['Std_Dev'], 3, show_legend=False)\n",
    "\n",
    "        # Update Layout\n",
    "        fig.update_layout(\n",
    "            title=f\"Convergence Analysis: {scen} (dataset: {dataset_name}, objectives: {objectives_key}, view: {view_mode.upper()})\",\n",
    "            height=500, width=1400, \n",
    "            template=\"plotly_white\",\n",
    "            legend=dict(orientation=\"h\", y=-0.15, x=0.5, xanchor=\"center\"),\n",
    "            margin=dict(l=50, r=50, t=80, b=80)\n",
    "        )\n",
    "        \n",
    "        # Y-axis independent scaling\n",
    "        fig.update_yaxes(title_text=\"RMSE\", row=1, col=1)\n",
    "        fig.update_yaxes(title_text=\"Count / Nodes\", row=1, col=2)\n",
    "        fig.update_yaxes(title_text=\"Std Dev\", row=1, col=3)\n",
    "\n",
    "        file_path = os.path.join(save_dir, f\"convergence_{scen}_VIEW_{view_mode.upper()}.png\")\n",
    "        fig.write_image(file_path)\n",
    "        print(f\"  -> Saved convergence: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparative boxplots between different scenarios\n",
    "def plot_boxplots(dataset_name, objectives_key, final_df, view_mode):\n",
    "    save_dir = os.path.join(OUTPUT_DIR, dataset_name, objectives_key)\n",
    "    \n",
    "    df_melt = final_df.melt(\n",
    "        id_vars=['Scenario'], \n",
    "        value_vars=['Train_RMSE', 'Test_RMSE'],\n",
    "        var_name='Type', value_name='RMSE'\n",
    "    )\n",
    "    \n",
    "    plt.figure(figsize=(12, 7))\n",
    "    sns.set_style(\"whitegrid\")\n",
    "\n",
    "    my_pal = {'Train_RMSE': COLORS['Train_RMSE'], 'Test_RMSE': COLORS['Test_RMSE']}\n",
    "\n",
    "    sns.boxplot(\n",
    "        data=df_melt, x='Scenario', y='RMSE', hue='Type',\n",
    "        palette=my_pal,\n",
    "        width=0.6, linewidth=1.2, showfliers=False \n",
    "    )\n",
    "    \n",
    "    sns.stripplot(\n",
    "        data=df_melt, x='Scenario', y='RMSE', hue='Type',\n",
    "        dodge=True, color='black', alpha=0.3, size=3, legend=False\n",
    "    )\n",
    "\n",
    "    plt.title(f'Final RMSE Distribution: {dataset_name} (Objectives: {objectives_key}, View: {view_mode.upper()})', fontsize=14)\n",
    "    plt.ylabel('RMSE')\n",
    "    plt.xlabel('Scenario')\n",
    "    plt.legend(title='Metric', loc='upper right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    filename = f\"boxplot_rmse_VIEW_{view_mode.upper()}.png\"\n",
    "    plt.savefig(os.path.join(save_dir, filename), dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"  -> Saved RMSE boxplot.\")\n",
    "\n",
    "    # (OPTIONAL) size boxplot\n",
    "    if 'Test_Size' in final_df.columns:\n",
    "        plt.figure(figsize=(12, 7))\n",
    "        sns.boxplot(\n",
    "            data=final_df, x='Scenario', y='Test_Size',\n",
    "            color=COLORS['Size'], width=0.5, showfliers=False\n",
    "        )\n",
    "        sns.stripplot(\n",
    "            data=final_df, x='Scenario', y='Test_Size',\n",
    "            color='black', alpha=0.3, size=3\n",
    "        )\n",
    "        plt.title(f'Final Tree Size Distribution: {dataset_name}', fontsize=14)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(save_dir, \"boxplot_size.png\"), dpi=300)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It does all statistical tests ( Friedman + Nemebyik) and keeps the reults txt.\n",
    "def run_stats(dataset_name, objectives_key, final_df, view_mode, save_dir):\n",
    "    pivot_df = final_df.pivot(index='Fold', columns='Scenario', values='Test_RMSE')\n",
    "\n",
    "    output_txt = [f\"=== Stats: {dataset_name} ({objectives_key}) ===\\n\"]\n",
    "    output_txt.append(pivot_df.describe().to_string() + \"\\n\\n\")\n",
    "    \n",
    "    # Friedman Test\n",
    "    try:\n",
    "        stat, p = sp.friedmanchisquare(*[pivot_df[col] for col in pivot_df.columns])\n",
    "        output_txt.append(f\"Friedman Test:\\nStatistic: {stat:.4f}, p-value: {p:.6f}\\n\")\n",
    "        \n",
    "        if p < 0.05:\n",
    "            output_txt.append(\"\\nSignificant differences found (p < 0.05). Nemenyi Post-Hoc:\\n\")\n",
    "            nemenyi = sp_post.posthoc_nemenyi_friedman(pivot_df)\n",
    "            output_txt.append(nemenyi.to_string())\n",
    "        else:\n",
    "            output_txt.append(\"\\nNo significant differences found between scenarios.\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        output_txt.append(f\"Error executing stats: {e}\")\n",
    "        \n",
    "    filename = f\"stats_VIEW_{view_mode.upper()}.txt\"\n",
    "    with open(os.path.join(save_dir, filename), \"w\") as f:\n",
    "        f.write(\"\".join(output_txt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function that calls \n",
    "def generate_all_plots(dataset_name, objectives_key='2_Objs', view_mode='main'):\n",
    "    print(f\"\\n--- Processing {dataset_name} [{objectives_key}] ---\")\n",
    "    \n",
    "    # loads data\n",
    "    history_data, final_df = load_data_for_analysis(dataset_name, objectives_key, view_mode)\n",
    "    \n",
    "    if final_df is None or final_df.empty:\n",
    "        print(\"No data found. Check your paths.\")\n",
    "        return\n",
    "\n",
    "    plot_convergence(dataset_name, objectives_key, history_data) #convergence using plotly\n",
    "    plot_boxplots(dataset_name, objectives_key, final_df)\n",
    "    run_stats(dataset_name, objectives_key, final_df)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Ex1: Cooling com 2 Objetivos\n",
    "#     generate_all_plots('Cooling', '2_Objs')\n",
    "    \n",
    "#     # Ex2: Cooling com 3 Objetivos (se já tiveres logs)\n",
    "#     # generate_all_plots('Cooling', '3_Objs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # for all datatsets, goes through all Objectives and all different View Modes\n",
    "    for ds in DATASETS:\n",
    "        for obj in OBJECTIVE_SETS:\n",
    "            print(f\"\\n{'#'*60}\")\n",
    "            print(f\"Processing: {ds} -> {obj}\")\n",
    "            print(f\"{'#'*60}\")\n",
    "            \n",
    "            for mode in ['main', 'rmse']:\n",
    "                generate_all_plots(ds, obj, mode)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
