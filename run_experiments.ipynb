{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATASETS A USAR, SENDO QUE POR AGORA QUEREMOS SÓ UM GRÁFICO PARA CADA #APAGAR\n",
    "\"\"\"\n",
    "load_resid_build_sale_price(X_y=True):\n",
    "    Loads and returns the RESIDNAME data set (regression). Taken from https://archive.ics.uci.edu/dataset/437/residential+building+data+set\n",
    "\n",
    "load_istanbul(X_y=True):\n",
    "    Loads and returns the Istanbul data set (regression). Taken from https://docs.1010data.com/MachineLearningExamples/IstanbulDataSet.html.\n",
    "\n",
    "load_airfoil(X_y=True):\n",
    "    - Number of data instances: 1503;\n",
    "    - Number of input features: 5;\n",
    "    - Target's range: [103.38-140.987].\n",
    "\n",
    "load_bike_sharing(X_y=True):\n",
    "    - Number of data instances: 17389;\n",
    "    - Number of input features: 13;\n",
    "    - Target's range: [22, 8714].                            x\n",
    "\n",
    "load_boston(X_y=True):\n",
    "    - Number of data instances: 506;\n",
    "    - Number of input features: 13;\n",
    "    - Target's range: [5, 50].\n",
    "\n",
    " load_concrete_slump\n",
    "    - Number of data instances: 103;\n",
    "    - Number of input features: 7;\n",
    "    - Target's range: [0, 29].\n",
    "\n",
    "load_concrete_strength(X_y=True):\n",
    "    - Number of data instances: 1005;\n",
    "    - Number of input features: 8;\n",
    "    - Target's range: [2.331807832, 82.5992248].\n",
    "\n",
    "load_diabetes(X_y=True):\n",
    "    - Number of data instances: 442;\n",
    "    - Number of input features: 10;\n",
    "    - Target's range: [25, 346].\n",
    "\n",
    "load_efficiency_heating(X_y=True):\n",
    "    - Number of data instances: 768;\n",
    "    - Number of input features: 8;\n",
    "    - Target's range: [6.01, 43.1].\n",
    "\n",
    "load_efficiency_cooling(X_y=True):<-------------- usar este\n",
    "    - Number of data instances: 768;\n",
    "    - Number of input features: 8;\n",
    "    - Target's range: [10.9, 48.03].\n",
    "\n",
    "load_forest_fires(X_y=True):\n",
    "    - Number of data instances: 513;\n",
    "    - Number of input features: 43;\n",
    "    - Target's range: [0.0, 6.995619625423205].\n",
    "\n",
    "load_parkinson_updrs(X_y=True):\n",
    "    - Number of data instances: 5875;                           x\n",
    "    - Number of input features: 19;\n",
    "    - Target's range: [7.0, 54.992].\n",
    "\n",
    "load_ld50(X_y=True):  <-----------------usar este\n",
    "    - Number of data instances: 234;\n",
    "    - Number of input features: 626;\n",
    "    - Target's range: [0.25, 8900.0].\n",
    "\n",
    "load_ppb(X_y=True): \n",
    "    - Number of data instances: 131;\n",
    "    - Number of input features: 626;\n",
    "    - Target's range: [0.5, 100.0]\n",
    "\n",
    "load_bioav(X_y=True):\n",
    "    - Number of data instances: 358;\n",
    "    - Number of input features: 241;\n",
    "    - Target's range: [0.4, 100.0].\n",
    "\"\"\"\n",
    "#APAGAR: hyperparameters\n",
    "\"\"\"\n",
    "(function) def mo_gp(\n",
    "    X_train: Tensor,\n",
    "    y_train: Tensor,\n",
    "    X_test: Tensor = None,\n",
    "    y_test: Tensor = None,\n",
    "    dataset_name: str = None,\n",
    "    pop_size: int = gp_parameters[\"pop_size\"],\n",
    "    selector_strategy: str = \"nested_tournament\",\n",
    "    survival_strategy: str = \"nsga2\",\n",
    "    offspring_size: int | None = None,\n",
    "    n_iter: int = gp_solve_parameters[\"n_iter\"],\n",
    "    p_xo: float = gp_parameters['p_xo'],\n",
    "    n_elites: int = gp_solve_parameters[\"n_elites\"],\n",
    "    max_depth: int | None = gp_solve_parameters[\"max_depth\"],\n",
    "    init_depth: int = gp_pi_init[\"init_depth\"],\n",
    "    log_path: str = None,\n",
    "    seed: int = gp_parameters[\"seed\"],\n",
    "    log_level: int = gp_solve_parameters[\"log\"],\n",
    "    verbose: int = gp_solve_parameters[\"verbose\"],\n",
    "    fitness_functions: list = mo_parameters[\"mo_fitness_functions\"],\n",
    "    minimization_flags: list = mo_parameters[\"mo_minimization_flags\"],\n",
    "    tournament_sizes: list = mo_parameters[\"mo_tournament_sizes\"],\n",
    "    ideal_candidate_values: list | None = None,\n",
    "    initializer: str = gp_parameters[\"initializer\"],\n",
    "    n_jobs: int = gp_solve_parameters[\"n_jobs\"],\n",
    "    prob_const: float = gp_pi_init[\"p_c\"],\n",
    "    tree_functions: list = list(FUNCTIONS.keys()),\n",
    "    tree_constants: list = [float(key.replace(\"constant_\", \"\").replace(\"_\", \"-\")) for key in CONSTANTS],\n",
    "    test_elite: bool = gp_solve_parameters[\"test_elite\"]\n",
    ") -> Any\n",
    "Main function to execute the Multi-Objective Genetic Programming (MOGP) algorithm on specified datasets\n",
    "\n",
    "Parameters\n",
    "X_train: : torch.Tensor\n",
    "Training input data.\n",
    "\n",
    "y_train: : torch.Tensor\n",
    "Training output data.\n",
    "\n",
    "X_test: : torch.Tensor , optional\n",
    "Testing input data.\n",
    "\n",
    "y_test: : torch.Tensor , optional\n",
    "Testing output data.\n",
    "\n",
    "dataset_name : str, optional\n",
    "Dataset name, for logging purposes\n",
    "\n",
    "pop_size : int, optional\n",
    "The population size for the genetic programming algorithm (default is 100).\n",
    "\n",
    "selector_strategy : str, optional\n",
    "The selection strategy for parent selection. Options are \"nested_tournament\" or \"nsga2\" (default is \"nested_tournament\").\n",
    "\n",
    "survival_strategy : str, optional\n",
    "The survival selection strategy. Options are \"nsga2\" or \"generational\" (default is \"nsga2\").\n",
    "\n",
    "offspring_size : int, optional\n",
    "The size of the offspring population to be generated in each generation. If None, it defaults to pop_size.\n",
    "\n",
    "n_iter : int, optional\n",
    "The number of iterations for the genetic programming algorithm (default is 100).\n",
    "\n",
    "p_xo : float, optional\n",
    "The probability of crossover in the genetic programming algorithm. Must be a number between 0 and 1 (default is 0.8).\n",
    "\n",
    "n_elites : int, optional\n",
    "The number of elites.\n",
    "\n",
    "max_depth : int, optional\n",
    "The maximum depth for the GP trees.\n",
    "\n",
    "init_depth : int, optional\n",
    "The depth value for the initial GP trees population.\n",
    "\n",
    "log_path : str, optional\n",
    "The path where is created the log directory where results are saved. Defaults to os.path.join(os.getcwd(), \"log\", \"mo_gp.csv\")\n",
    "\n",
    "seed : int, optional\n",
    "Seed for the randomness\n",
    "\n",
    "log_level : int, optional\n",
    "Level of detail to utilize in logging.\n",
    "\n",
    "verbose : int, optional\n",
    "Level of detail to include in console output.\n",
    "\n",
    "fitness_functions : list, optional\n",
    "A list of fitness function names, one for each objective. (Default is from mo_parameters)\n",
    "\n",
    "minimization_flags : list, optional\n",
    "A list of booleans indicating if each corresponding objective is for minimization (True) or maximization (False). (Default is from mo_parameters)\n",
    "\n",
    "tournament_sizes : list, optional\n",
    "A list of integers defining the tournament size for each objective during Nested Tournament Selection. (Default is from mo_parameters)\n",
    "\n",
    "ideal_candidate_values : list, optional\n",
    "A list of ideal candidate values for each objective to guide elite selection. If None, defaults uses first-objective logic.\n",
    "\n",
    "initializer : str, optional\n",
    "The strategy for initializing the population (e.g., \"grow\", \"full\", \"rhh\").\n",
    "\n",
    "n_jobs : int, optional\n",
    "Number of parallel jobs to run (default is 1).\n",
    "\n",
    "prob_const : float, optional\n",
    "The probability of a constant being chosen rather than a terminal in trees creation (default: 0.2).\n",
    "\n",
    "tree_functions : list, optional\n",
    "List of allowed functions that can appear in the trees. Check documentation for the available functions.\n",
    "\n",
    "tree_constants : list, optional\n",
    "List of constants allowed to appear in the trees.\n",
    "\n",
    "test_elite : bool, optional\n",
    "Whether to test the elite individual on the test set after each generation.\n",
    "\n",
    "Returns\n",
    "MultiObjectiveTree\n",
    "Returns the best individual according to the tracking strategy at the last generation.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Tornament Size could be more \"flexible\"\n",
    "For instance, 5% of pop_size (but has to be >1)\n",
    "    t_size_val = int(params['pop_size'] * 0.05) \n",
    "    t_sizes = [max(2, t_size_val)] * n_objs\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#APAGAR CENÁRIO CD ELITISM\n",
    "#1. best candidate elitism; \n",
    "#2. rank+ CD elitism\n",
    "# Para criar o cenário de NT + rank/CD elitism: Rank Elitism no Generational, terias de alterar o main_mo_gp.py. \n",
    "# # Em main_mo_gp.py\n",
    "\n",
    "# def mo_gp(..., elitism_type=\"standard\", ...): # Novo argumento\n",
    "    \n",
    "#     # ... (validações) ...\n",
    "\n",
    "#     # Lógica de Elitismo Atualizada\n",
    "#     if ideal_candidate_values is not None:\n",
    "#         gp_parameters[\"find_elit_func\"] = lambda pop, n, min_flags, fronts=None: \\\n",
    "#             find_mo_elites_ideal_candidate(pop, n, min_flags, ideal_candidate_values)\n",
    "            \n",
    "#     elif survival_strategy == \"generational\" and n_elites > 0:\n",
    "#         if elitism_type == \"first_obj\":\n",
    "#              # Elitismo no 1º Objetivo\n",
    "#              gp_parameters[\"find_elit_func\"] = lambda pop, n, min_flags, fronts=None: \\\n",
    "#                  find_mo_elites_default(pop, n, min_flags, use_first_obj=True, fronts=fronts)\n",
    "#         else:\n",
    "#              # Elitismo Padrão (Rank + CD) -> O que tu queres adicionar\n",
    "#              gp_parameters[\"find_elit_func\"] = find_mo_elites_default\n",
    "             \n",
    "#     else:\n",
    "#         gp_parameters[\"find_elit_func\"] = find_mo_elites_default\n",
    "\n",
    "\n",
    "\n",
    "# 'NT_1st_Obj_Elitism': {\n",
    "#         'selector': 'nested_tournament',\n",
    "#         'survival': 'generational',\n",
    "#         'n_elites': 1,\n",
    "#         'elitism_type': 'first_obj', # <-- Flag Nova\n",
    "#         'ideal': None\n",
    "#     },\n",
    "\n",
    "# 'NT_Rank_CD_Elitism': { \n",
    "#         'selector': 'nested_tournament',\n",
    "#         'survival': 'generational',\n",
    "#         'n_elites': 1,\n",
    "#         'elitism_type': 'standard',\n",
    "#         'ideal': None\n",
    "#     }\n",
    "\n",
    "\n",
    "# # Dentro do loop de execução\n",
    "# elitism_type = scen_config.get('elitism_type', 'standard')\n",
    "\n",
    "# elite = mo_gp(\n",
    "#     # ... outros argumentos ...\n",
    "#     elitism_type=elitism_type,\n",
    "#     # ...\n",
    "# )\n",
    "####################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALTERAÇÕES (APAGAR):\n",
    "#- log_path & log_level: posso criar um log =5 e fazer hard coded o que quero armazenar. LOG=5 DO QUE FOR PRECISO (AUDIO PROF. KARINA); \n",
    "#- ideal candidate ser atualizado; BEST INDIVIDUAL IMPLEMENTAR BEM E DEIXA DE SER USER DEFINED; \n",
    "#Manter um histórico utilizando a pop. que evolui e para cada objetivo de cada vez que encontra um indivíduo \n",
    "#com erro menor de sempre, aquele valor atualizada: lista que muda dinamicamente e inicializada com os melhores valores da pop inicial\n",
    "\n",
    "#- implementar bem o CD como elitism (mesmo acima) ADICIONAR ELITISMO DE RANK+CD PARA NT\n",
    "#- tournament size mas ver com \"Tornament Size could be ...\"\n",
    "#- #RANDOM_SEARCH DEIXA DE SE FAZER APAGAR\n",
    "#- QUAIS ERAM AS FITNESS FUNCTIONS? APAGAR: TEMOS 3 NOVAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import plotly.graph_objects as go ##APAGAR\n",
    "from sklearn.model_selection import KFold, ParameterGrid\n",
    "from slim_gsgp.main_mo_gp import mo_gp\n",
    "from slim_gsgp.datasets.data_loader import (\n",
    "     load_efficiency_cooling, load_ld50\n",
    ")\n",
    "\n",
    "# Configuration\n",
    "RANDOM_SEED = 37\n",
    "np.random.seed(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "# Datasets to Test (we need to import them first)\n",
    "DATASETS = {\n",
    "    'Cooling': load_efficiency_cooling,\n",
    "    'Toxicity': load_ld50,\n",
    "}\n",
    "\n",
    "\n",
    "# Objective Configurations\n",
    "OBJECTIVE_SETS = {\n",
    "    '2_Objs': {\n",
    "        'funcs': [\"rmse\", \"size\"],\n",
    "        'flags': [True, True] # Min, Min\n",
    "    },\n",
    "    '3_Objs': {\n",
    "        'funcs': [\"rmse\", \"size\", \"features\"],\n",
    "        'flags': [True, True, True]\n",
    "    },\n",
    "    '5_Objs': {\n",
    "        'funcs': [\"rmse\", \"size\", \"features\", \"nao\", \"naoc\"],\n",
    "        'flags': [True, True, True, True, True]\n",
    "    }\n",
    "}\n",
    "\n",
    "# algorithms/configurations to test\n",
    "SCENARIOS = {\n",
    "    'NSGA-II_Pure': {\n",
    "        'selector': 'nsga2',\n",
    "        'survival': 'nsga2',\n",
    "        'n_elites': 0 # Not used when we use NSGA-II elitism/survival\n",
    "    },\n",
    "    'NT_NSGA-II': {\n",
    "        'selector': 'nested_tournament',\n",
    "        'survival': 'nsga2',\n",
    "        'n_elites': 0\n",
    "    },\n",
    "    'NT_No_Elitism': {\n",
    "        'selector': 'nested_tournament',\n",
    "        'survival': 'generational',\n",
    "        'n_elites': 0\n",
    "    },\n",
    "    'NT_1st_Obj_Elitism': {\n",
    "        'selector': 'nested_tournament',\n",
    "        'survival': 'generational',\n",
    "        'n_elites': 1,  #when we try to optimize for 1 criterion only, it's better to have only 1 elite because it can take over the population (we want diversity)                                                     \n",
    "        'ideal': None # Triggers 1st obj logic in the main_mo_gp\n",
    "    },\n",
    "## #I STILL HAVE TO IMPLEMENT THESE TWO BELOW\n",
    "##APAGAR: A IDEIA SERIA TER O MELHOR VALOR POSSÍVEL QUE JÁ FOI VISTO PARA CADA OBJETIVO\n",
    "##APAGAR: USAR A IDEIA DE NT COM ELITISM DE NSGA-II, OU SEJA, MANTER DA 1º PF OS COM MAIOR CD E PASSAR PARA A PRÓXIMA PF ATÉ COMPLETAR O NÚMERO DE ELITES\n",
    "    ## 'NT_Ideal_Cand_Elitism': {\n",
    "    ##     'selector': 'nested_tournament',\n",
    "    ##     'survival': 'generational',\n",
    "    ##     'n_elites': 1,                      \n",
    "    ##     'ideal': 'DYNAMIC' # Placeholder tag\n",
    "    ## },\n",
    "    ## 'NT_Rank_CD_Elitism': {\n",
    "    ##     'selector': 'nested_tournament',\n",
    "    ##     'survival': 'generational',\n",
    "    ##     'n_elites': 1,\n",
    "    ##     'elitism_type': 'standard' # Flag para Rank+CD (requer alteração no main_mo_gp)\n",
    "    ## }\n",
    "}\n",
    "\n",
    "# Hyperparameter Grid for Inner CV\n",
    "PARAM_GRID = {\n",
    "    'pop_size': [100, 250, 500],\n",
    "    'n_iter': [500],                                            #APAGAR: Pode ser que seja um valor muito alto\n",
    "    'p_xo': [0.2, 0.5, 0.8],\n",
    "    'prob_const': [0.2],     \n",
    "    'max_depth': [17],       #default\n",
    "    'initializer': ['rhh'],  #default\n",
    "    \"init_depth\": [6],       #default\n",
    "    \"seed\": [74],            #default\n",
    "    \"verbose\": [1],          #default\n",
    "    \"n_jobs\": [1],           #default\n",
    "    \"test_elite\": [True]    \n",
    "}\n",
    "\n",
    "##################################JUST COMMENTS##################################\n",
    "#Other parameters will remain default:\n",
    "###offspring_size###\n",
    "# if offspring_size is None:\n",
    "#     n_offspring = self.pop_size\n",
    "\n",
    "###n_elites###\n",
    "# it depends on the scenario being used\n",
    "\n",
    "###log_path & log_level###\n",
    "#posso criar um log =5 e fazer hard coded o que quero armazenar    APAGAR\n",
    "# it depends on dataset, scenario, fold, hyperparams\n",
    "# APAGAR: find out what information we need to log (its better to log more info and then ignore what is not needed than the opposite)\n",
    "\n",
    "###fitness_functions, minimization_flags###\n",
    "#it depends on the scenario being used: OBJECTIVE_SETS (Ok)\n",
    "\n",
    "###tournament_sizes###\n",
    "# Tournament sizes need to be dynamic based on n_objectives, handled in loop. When using Nested Tournament Selection, but for now we will fix it \n",
    "\n",
    "###ideal_candidate_values###\n",
    "# it can no longer be user defined      \n",
    "\n",
    "### \"test_elite\": True###\n",
    "\n",
    "### tree_functions ###\n",
    "# FUNCTIONS = {\n",
    "#     'add': {'function': torch.add, 'arity': 2},\n",
    "#     'subtract': {'function': torch.sub, 'arity': 2},\n",
    "#     'multiply': {'function': torch.mul, 'arity': 2},\n",
    "#     'divide': {'function': utils.protected_div, 'arity': 2},\n",
    "#     'mod': {'function': utils.protected_mod, 'arity': 2},\n",
    "#     'pow': {'function': utils.protected_pow, 'arity': 2},\n",
    "# }\n",
    "\n",
    "### tree_constants ###\n",
    "# I changed what originaly was in gp_config.py to the following:\n",
    "# random.seed(47)\n",
    "# CONSTANTS = {\n",
    "#     f'constant_{i}': lambda _, val=random.uniform(-1, 1): torch.tensor(val)\n",
    "#     for i in range(10)\n",
    "# }\n",
    "#################################################################################\n",
    "\n",
    "\n",
    "K_OUTER = 15\n",
    "K_INNER = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#e5c120ff; padding:1px; border-radius:10px;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Evaluation Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For each dataset: load data\n",
    "    # For each Outer fold: (14 folds for train + 1 fold for test each time) -> what will be use to track scores\n",
    "        # For each objective structure (Obj: 2, 3, 5)\n",
    "            # For each Scenario\n",
    "                # For each combination of current_grid# Estrutura: \n",
    "    \n",
    "#./log_mo/DATASET/SCENARIO/OBJECTIVES/fold_X.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ds_name, loader_func in DATASETS.items():\n",
    "    print(f\"\\n{'='*40}\\nDataset: {ds_name}\\n{'='*40}\")\n",
    "    \n",
    "    # Load Data (X: features, y: target)\n",
    "    X, y = loader_func(X_y=True)\n",
    "    \n",
    "    # Outer CV (14 folds for train + 1 fold for test each time)\n",
    "    kf_outer = KFold(n_splits=K_OUTER, shuffle=True, random_state=RANDOM_SEED)\n",
    "    \n",
    "    for outer_fold, (train_idx, test_idx) in enumerate(kf_outer.split(X, y)):\n",
    "        print(f\"\\n  > Outer Fold {outer_fold+1}/{K_OUTER}\")\n",
    "        \n",
    "        X_train_outer = X[train_idx]\n",
    "        y_train_outer = y[train_idx]\n",
    "        X_test_outer = X[test_idx]\n",
    "        y_test_outer = y[test_idx]\n",
    "        \n",
    "        # Inner CV Setup\n",
    "        kf_inner = KFold(n_splits=K_INNER, shuffle=True, random_state=RANDOM_SEED)\n",
    "        \n",
    "        for obj_set_name, obj_config in OBJECTIVE_SETS.items():\n",
    "            n_objs = len(obj_config['funcs'])\n",
    "            print(f\"    > Objectives: {obj_set_name}\")\n",
    "            \n",
    "            for scen_name, scen_config in SCENARIOS.items():\n",
    "                print(f\"      > Scenario: {scen_name}\")\n",
    "                \n",
    "                # Hyperparameter Tuning (Inner CV)\n",
    "                best_params = None\n",
    "                best_inner_score = float('inf') # Min RMSE of validation\n",
    "                \n",
    "                # All possible parameter configurations\n",
    "                current_grid = list(ParameterGrid(PARAM_GRID))\n",
    "                \n",
    "                for params in current_grid:\n",
    "                    # tournament sizes probably has a big impact but let's leave it constant for now\n",
    "                    t_sizes = [2] * n_objs\n",
    "\n",
    "                    inner_rmse_scores = []\n",
    "\n",
    "                    ## #I STILL HAVE TO IMPLEMENT THESE TWO BELOW\n",
    "                    ## # Adjust ideal candidate vector size if needed\n",
    "                    ## current_ideal = None\n",
    "                    ## if 'ideal' in scen_config and scen_config['ideal'] is not None:\n",
    "                    ##     current_ideal = [0.0] * n_objs\n",
    "\n",
    "                    # Loop Inner CV: trains in (k_inner -1) folds, validates in 1 fold\n",
    "                    for inner_t_idx, inner_v_idx in kf_inner.split(X_train_outer, y_train_outer):\n",
    "                        X_in_t, y_in_t = X_train_outer[inner_t_idx], y_train_outer[inner_t_idx]\n",
    "                        X_in_v, y_in_v = X_train_outer[inner_v_idx], y_train_outer[inner_v_idx]\n",
    "                        \n",
    "                        # Run MOGP (I suppress output for inner loops)\n",
    "                        try:\n",
    "                            elite = mo_gp(\n",
    "                                X_train=X_in_t, y_train=y_in_t,\n",
    "                                X_test=X_in_v, y_test=y_in_v,\n",
    "                                dataset_name=f\"{ds_name}_inner\",\n",
    "                                fitness_functions=obj_config['funcs'],\n",
    "                                minimization_flags=obj_config['flags'],\n",
    "                                tournament_sizes=t_sizes,\n",
    "                                ##ideal_candidate_values=current_ideal,\n",
    "                                selector_strategy=scen_config['selector'],\n",
    "                                survival_strategy=scen_config['survival'],\n",
    "                                n_elites=scen_config['n_elites'],\n",
    "                                log_level=0, verbose=0, **params # No logging for inner\n",
    "                            )\n",
    "                            # validation RMSE:find_mo_elites_default returns elite with test_fitness already calculated  \n",
    "                            val_rmse = float(elite.test_fitness[0]) \n",
    "                            inner_rmse_scores.append(val_rmse)\n",
    "\n",
    "                        except Exception as e:\n",
    "                            # for debug\n",
    "                            inner_rmse_scores.append(float('inf'))\n",
    "                    \n",
    "                    # The winner is the one with the lowest median RMSE in validation\n",
    "                    median_rmse = np.median(inner_rmse_scores)\n",
    "                    \n",
    "                    if median_rmse < best_inner_score:\n",
    "                        best_inner_score = median_rmse\n",
    "                        best_params = params.copy()\n",
    "                        best_params['tournament_sizes'] = t_sizes   # Store the calculated list \n",
    "                        ## best_params['ideal_candidate_values'] = current_ideal\n",
    "                        \n",
    "                # Setup Log Directory: ./log_mo / Dataset / Cenario / Objetivos / fold_X /\n",
    "                fold_dir = f\"./log_mo/{ds_name}/{scen_name}/{obj_set_name}/fold_{outer_fold+1}\"\n",
    "                if not os.path.exists(fold_dir):\n",
    "                    os.makedirs(fold_dir)\n",
    "                \n",
    "                # Save CSV of Winner Hyperparameters\n",
    "                # remove tournament_sizes from csv to make it cleaner\n",
    "                if 'tournament_sizes' in best_params: del best_params['tournament_sizes'] \n",
    "                \n",
    "                #just to have the inner score saved\n",
    "                best_params['Median_Inner_RMSE'] = best_inner_score\n",
    "\n",
    "                pd.DataFrame([best_params]).to_csv(os.path.join(fold_dir, \"best_inner_params.csv\"), index=False)\n",
    "                \n",
    "                print(f\"        > Best Params: {best_params} (RMSE Val: {best_inner_score:.4f})\")\n",
    "\n",
    "                # final training with best hyperparameters on the outer fold\n",
    "                log_path = os.path.join(fold_dir, \"execution_log.csv\")\n",
    "\n",
    "                t_sizes_final = [2] * n_objs #needs to be recalculated here again because I dropped it before\n",
    "                \n",
    "                try:\n",
    "                    mo_gp(\n",
    "                        X_train=X_train_outer, y_train=y_train_outer,\n",
    "                        X_test=X_test_outer, y_test=y_test_outer,\n",
    "                        dataset_name=ds_name,\n",
    "                        fitness_functions=obj_config['funcs'],\n",
    "                        minimization_flags=obj_config['flags'],\n",
    "                        tournament_sizes=t_sizes_final,\n",
    "                        ##ideal_candidate_values=best_params['ideal_candidate_values'],\n",
    "                        selector_strategy=scen_config['selector'],\n",
    "                        survival_strategy=scen_config['survival'],\n",
    "                        n_elites=scen_config['n_elites'],\n",
    "                        # use winner params found\n",
    "                        pop_size=best_params['pop_size'],\n",
    "                        n_iter=best_params['n_iter'],\n",
    "                        p_xo=best_params['p_xo'],\n",
    "                        prob_const=best_params['prob_const'],\n",
    "                        max_depth=best_params['max_depth'],\n",
    "                        verbose=0, \n",
    "                        log_level=5,\n",
    "                        log_path=log_path,\n",
    "                        n_jobs=1\n",
    "                    )\n",
    "                    print(f\"        > Log saved at: {log_path}\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"      [Outer Error] {e}\")\n",
    "                    import traceback\n",
    "                    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import scipy.stats as sp\n",
    "import scikit_posthocs as sp_post\n",
    "\n",
    "# configuration\n",
    "LOG_DIR = './log_mo'       # where logs are stored\n",
    "OUTPUT_DIR = './plots_mo'  #where I'll save the plots\n",
    "\n",
    "COLORS = {\n",
    "    'train': '#1f77b4',\n",
    "    'test': '#ff7f0e',\n",
    "    'std': '#9467bd'\n",
    "}\n",
    "\n",
    "OBJ_MAP = {\n",
    "    0: \"RMSE\",\n",
    "    1: \"Size\",\n",
    "    2: \"Features\",\n",
    "    3: \"NAO\",\n",
    "    4: \"NAOC\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforms a column with \"5.1|10.2\" strings into a DataFrame of floats\n",
    "def parse_fitness_column(series):\n",
    "    # Remove \"N/A\" entries\n",
    "    valid = series[series != \"N/A\"]\n",
    "    if valid.empty:\n",
    "        return None\n",
    "    return valid.str.split('|', expand=True).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function goes through the log folders and loads the raw data from all scenarios and folds\n",
    "#It returns:\n",
    "# 1. history_data: Dictionary with generation-by-generation evolution (for Convergence Plots)\n",
    "# 2. final_data: DataFrame with the last generation of each fold (for Boxplots and Stats)\n",
    "def load_data_for_analysis(dataset_name, objectives_key):\n",
    "    target_path = os.path.join(LOG_DIR, dataset_name)\n",
    "    \n",
    "    if not os.path.exists(target_path):\n",
    "        print(f\"[ERROR] Folder not found: {target_path}\")\n",
    "        return None, None\n",
    "\n",
    "    # Find available scenarios (e.g., NSGA-II_Pure, NT_NSGA-II...)\n",
    "    scenarios = [d for d in os.listdir(target_path) if os.path.isdir(os.path.join(target_path, d))]\n",
    "    \n",
    "    history_data = {} # {scenario: [list of dataframes per fold]}\n",
    "    final_rows = []   # list of dicts for final stats\n",
    "\n",
    "    print(f\"Logs from {dataset_name} dataset with these objectives: {objectives_key}\")\n",
    "\n",
    "    for scen in scenarios:\n",
    "        # Path: ./log_mo/Dataset/Scenario/2_Objs/fold_*/execution_log.csv\n",
    "        pattern = os.path.join(target_path, scen, objectives_key, \"fold_*\", \"execution_log.csv\")\n",
    "        files = glob.glob(pattern)\n",
    "        \n",
    "        if not files:\n",
    "            continue\n",
    "            \n",
    "        history_data[scen] = []\n",
    "        \n",
    "        for f in files:\n",
    "            try:\n",
    "                df = pd.read_csv(f)\n",
    "                \n",
    "                #I assumed that:               Gen, Time, Elite_Fit_Train, Nodes, Elite_Fit_Test, ...\n",
    "                # 3rd col is always Elite_Fit_Train (RMSE)\n",
    "                # 5th col is always Elite_Fit_Test (RMSE)   \n",
    "                train_fits_df = parse_fitness_column(df.iloc[:, 2])\n",
    "                test_fits_df = parse_fitness_column(df.iloc[:, 4])\n",
    "                \n",
    "                #get a clean DataFrame with relevant info to plot\n",
    "                clean_df = pd.DataFrame({\n",
    "                    'Generation': df.iloc[:, 0],\n",
    "                    'Std_RMSE': df.iloc[:, -2] if df.shape[1] >= 7 else np.nan\n",
    "                })\n",
    "                \n",
    "                # Add train cols for each objective\n",
    "                if train_fits_df is not None:\n",
    "                    for col_idx in train_fits_df.columns:\n",
    "                        metric_name = OBJ_MAP.get(col_idx, f\"Obj_{col_idx}\")\n",
    "                        clean_df[f'Train_{metric_name}'] = train_fits_df[col_idx]\n",
    "                \n",
    "                \n",
    "                # Add test cols for each objective\n",
    "                if test_fits_df is not None:\n",
    "                    for col_idx in test_fits_df.columns:\n",
    "                        metric_name = OBJ_MAP.get(col_idx, f\"Obj_{col_idx}\")\n",
    "                        clean_df[f'Test_{metric_name}'] = test_fits_df[col_idx]\n",
    "                \n",
    "                history_data[scen].append(clean_df)\n",
    "                \n",
    "                # last generation for boxplot\n",
    "                last_row = clean_df.iloc[-1]\n",
    "                fold_num = f.split(os.sep)[-2].split('_')[-1] # Extract '1' from 'fold_1'\n",
    "                \n",
    "                final_rows.append({\n",
    "                    'Dataset': dataset_name,\n",
    "                    'Scenario': scen,\n",
    "                    'Fold': int(fold_num),\n",
    "                    'Train_RMSE': last_row.get('Train_RMSE', np.nan),\n",
    "                    'Test_RMSE': last_row.get('Test_RMSE', np.nan)\n",
    "                })\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"  [WARN] Fail reading {f}: {e}\")\n",
    "\n",
    "    final_df = pd.DataFrame(final_rows)\n",
    "    return history_data, final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convergence plot: meadian + IQR (generations, objective)\n",
    "def plot_convergence(dataset_name, objectives_key, history_data):\n",
    "    save_dir = os.path.join(OUTPUT_DIR, dataset_name, objectives_key)\n",
    "    if not os.path.exists(save_dir): os.makedirs(save_dir)\n",
    "\n",
    "    for scen, folds_list in history_data.items():\n",
    "        if not folds_list: continue\n",
    "\n",
    "        # Get metrics that start with \"train_\"\n",
    "        sample_df = folds_list[0]\n",
    "        metrics = [c.replace(\"Train_\", \"\") for c in sample_df.columns if c.startswith(\"Train_\")]\n",
    "\n",
    "        min_len = min([len(df) for df in folds_list])\n",
    "        generations = np.arange(min_len)\n",
    "\n",
    "        # Subplots setup: 1 per objective/metric + 1 for std\n",
    "        total_plots = len(metrics) + 1\n",
    "        subplot_titles = metrics + [\"Pop RMSE Std Dev\"]\n",
    "        \n",
    "        fig = make_subplots(\n",
    "            rows=1, cols=total_plots,\n",
    "            subplot_titles=subplot_titles,\n",
    "            horizontal_spacing=0.05\n",
    "        )\n",
    "\n",
    "        # Helper function to draw: Median + IQR\n",
    "        def add_iqr_trace(metric_name, mode, color, col_idx, show_legend=False):\n",
    "            col_name = f\"{mode}_{metric_name}\" # Ex: Train_RMSE\n",
    "            \n",
    "            # get [folds, generations] ,atrix\n",
    "            data = np.array([df[col_name].values[:min_len] for df in folds_list])\n",
    "            \n",
    "            median = np.median(data, axis=0)\n",
    "            q1 = np.percentile(data, 25, axis=0)\n",
    "            q3 = np.percentile(data, 75, axis=0)\n",
    "            \n",
    "            # IQR\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=np.concatenate([generations, generations[::-1]]),\n",
    "                y=np.concatenate([q3, q1[::-1]]),\n",
    "                fill='toself', fillcolor=color, opacity=0.2,\n",
    "                line=dict(color='rgba(255,255,255,0)'), showlegend=False,\n",
    "                name=f'{mode} IQR'\n",
    "            ), row=1, col=col_idx)\n",
    "            \n",
    "            # Median\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=generations, y=median, mode='lines', name=f'{mode} {metric_name}',\n",
    "                line=dict(color=color), showlegend=show_legend\n",
    "            ), row=1, col=col_idx)\n",
    "\n",
    "        # loop through each objective/metric\n",
    "        for i, metric in enumerate(metrics):\n",
    "            col_idx = i + 1\n",
    "            # Jegend only for the the first one\n",
    "            show_leg = (i == 0)\n",
    "            \n",
    "            # Train (blue)\n",
    "            add_iqr_trace(metric, \"Train\", COLORS['train'], col_idx, show_leg)\n",
    "            # Test (orange)\n",
    "            add_iqr_trace(metric, \"Test\", COLORS['test'], col_idx, show_leg)\n",
    "\n",
    "        # Std Dev APAGAR: SÓ 1 LINHA?\n",
    "        std_data = np.array([df['Std_RMSE'].values[:min_len] for df in folds_list])\n",
    "        s_med = np.median(std_data, axis=0)\n",
    "        s_q1 = np.percentile(std_data, 25, axis=0)\n",
    "        s_q3 = np.percentile(std_data, 75, axis=0)\n",
    "        \n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=np.concatenate([generations, generations[::-1]]),\n",
    "            y=np.concatenate([s_q3, s_q1[::-1]]),\n",
    "            fill='toself', fillcolor=COLORS['std'], opacity=0.2, line=dict(width=0), showlegend=False\n",
    "        ), row=1, col=total_plots)\n",
    "        \n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=generations, y=s_med, mode='lines', name='RMSE Std Dev',\n",
    "            line=dict(color=COLORS['std'])\n",
    "        ), row=1, col=total_plots)\n",
    "\n",
    "        # Layout\n",
    "        fig.update_layout(\n",
    "            title=f\"Convergence: {scen} - {dataset_name} ({objectives_key})\",\n",
    "            height=500, width=350 * total_plots, \n",
    "            template=\"plotly_white\",\n",
    "            legend=dict(orientation=\"h\", y=-0.2, x=0.5, xanchor=\"center\")\n",
    "        )\n",
    "        \n",
    "        file_path = os.path.join(save_dir, f\"convergence_{scen}.png\")\n",
    "        fig.write_image(file_path)\n",
    "        print(f\"  -> Saved convergence plot: {file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparative boxplots between different scenarios\n",
    "def plot_boxplots(dataset_name, objectives_key, final_df):\n",
    "    save_dir = os.path.join(OUTPUT_DIR, dataset_name, objectives_key)\n",
    "    \n",
    "    df_melt = final_df.melt(\n",
    "        id_vars=['Scenario'], \n",
    "        value_vars=['Train_RMSE', 'Test_RMSE'],\n",
    "        var_name='Type', value_name='RMSE'\n",
    "    )\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    \n",
    "    sns.boxplot(\n",
    "        data=df_melt, x='Scenario', y='RMSE', hue='Type',\n",
    "        palette=[COLORS['train'], COLORS['test']],\n",
    "        width=0.5, linewidth=1.5, showfliers=False # hide extreme outliers so we can look better at graph\n",
    "    )\n",
    "    \n",
    "    # Adicionar pontos individuais (swarmplot) para ver a distribuição real (os 15 folds)\n",
    "    sns.stripplot(\n",
    "        data=df_melt, x='Scenario', y='RMSE', hue='Type',\n",
    "        dodge=True, color='black', alpha=0.4, size=4, legend=False\n",
    "    )\n",
    "\n",
    "    plt.title(f'Final RMSE Distribution: {dataset_name} ({objectives_key})', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(save_dir, \"boxplot_comparison.png\"), dpi=300)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It does all statistical tests ( Friedman + Nemebyik) and keeps the reults txt.\n",
    "def run_stats(dataset_name, objectives_key, final_df):\n",
    "    save_dir = os.path.join(OUTPUT_DIR, dataset_name, objectives_key)\n",
    "    \n",
    "    pivot_df = final_df.pivot(index='Fold', columns='Scenario', values='Test_RMSE')\n",
    "\n",
    "    output_txt = [f\"=== Stats: {dataset_name} ({objectives_key}) ===\\n\"]\n",
    "    output_txt.append(pivot_df.describe().to_string() + \"\\n\\n\")\n",
    "    \n",
    "    # Friedman Test\n",
    "    try:\n",
    "        stat, p = sp.friedmanchisquare(*[pivot_df[col] for col in pivot_df.columns])\n",
    "        output_txt.append(f\"Friedman Test:\\nStatistic: {stat:.4f}, p-value: {p:.6f}\\n\")\n",
    "        \n",
    "        if p < 0.05:\n",
    "            output_txt.append(\"\\nSignificant differences found (p < 0.05). Running Nemenyi...\\n\")\n",
    "            nemenyi = sp_post.posthoc_nemenyi_friedman(pivot_df)\n",
    "            output_txt.append(nemenyi.to_string())\n",
    "        else:\n",
    "            output_txt.append(\"\\nNo significant differences found between scenarios.\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        output_txt.append(f\"Error executing stats: {e}\")\n",
    "        \n",
    "\n",
    "    with open(os.path.join(save_dir, \"stats.txt\"), \"w\") as f:\n",
    "        f.write(\"\".join(output_txt))\n",
    "    print(f\"  -> Saved stats.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function that calls \n",
    "def generate_all_plots(dataset_name, objectives_key='2_Objs'):\n",
    "    print(f\"\\n--- Processing {dataset_name} [{objectives_key}] ---\")\n",
    "    \n",
    "    # 1loads data\n",
    "    history_data, final_df = load_data_for_analysis(dataset_name, objectives_key)\n",
    "    \n",
    "    if final_df is None or final_df.empty:\n",
    "        print(\"No data found. Check your paths.\")\n",
    "        return\n",
    "\n",
    "    plot_convergence(dataset_name, objectives_key, history_data) #convergence using plotly\n",
    "    plot_boxplots(dataset_name, objectives_key, final_df)\n",
    "    run_stats(dataset_name, objectives_key, final_df)\n",
    "\n",
    "\n",
    "# --- EXEMPLO DE USO ---\n",
    "if __name__ == \"__main__\":\n",
    "    # Podes correr isto quantas vezes quiseres sem treinar nada!\n",
    "    \n",
    "    # Exemplo 1: Cooling com 2 Objetivos\n",
    "    generate_all_plots('Cooling', '2_Objs')\n",
    "    \n",
    "    # Exemplo 2: Cooling com 3 Objetivos (se já tiveres logs)\n",
    "    # generate_all_plots('Cooling', '3_Objs')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
